{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0b37168",
   "metadata": {},
   "source": [
    "# 4. –¢–∞“£–±–∞–ª–∞–Ω–±–∞“ì–∞–Ω –¥–µ—Ä–µ–∫—Ç–µ—Ä–º–µ–Ω –∂–∞—Ç—Ç—ã“õ—Ç—ã—Ä—É\n",
    "# 4. –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acdb7f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.0\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.8.0\n",
      "torch version: 2.5.1\n",
      "tensorflow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"tiktoken\", \n",
    "        \"torch\",\n",
    "        \"tensorflow\" # For OpenAI's pretrained weights\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd92bbe",
   "metadata": {},
   "source": [
    "- –ë“±–ª —Ç–∞—Ä–∞—É–¥–∞ –±—ñ–∑ LLM-–¥—ñ –∞–ª–¥—ã–Ω –∞–ª–∞ –æ“õ—ã—Ç—É “Ø—à—ñ–Ω –æ“õ—ã—Ç—É —Ü–∏–∫–ª—ñ–Ω –∂”ô–Ω–µ –º–æ–¥–µ–ª—å –±–∞“ì–∞–ª–∞—É–¥—ã“£ “õ–∞—Ä–∞–ø–∞–π—ã–º —Ç“Ø—Ä—ñ–Ω —ñ—Å–∫–µ –∞—Å—ã—Ä–∞–º—ã–∑.\n",
    "- –û—Å—ã —Ç–∞—Ä–∞—É–¥—ã“£ —Å–æ“£—ã–Ω–¥–∞ –±—ñ–∑ —Å–æ–Ω–¥–∞–π-–∞“õ OpenAI-–¥—ã“£ –∞—à—ã“õ “õ–æ–ª–∂–µ—Ç—ñ–º–¥—ñ –∞–ª–¥—ã–Ω –∞–ª–∞ –æ“õ—ã—Ç—ã–ª“ì–∞–Ω —Å–∞–ª–º–∞“õ—Ç–∞—Ä—ã–Ω –º–æ–¥–µ–ª—ñ–º—ñ–∑–≥–µ –∂“Ø–∫—Ç–µ–π–º—ñ–∑.\n",
    "\n",
    "- –í —ç—Ç–æ–π –≥–ª–∞–≤–µ –º—ã —Ä–µ–∞–ª–∏–∑—É–µ–º —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è –∏ –±–∞–∑–æ–≤—É—é –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏—è LLM.\n",
    "- –í –∫–æ–Ω—Ü–µ —ç—Ç–æ–π –≥–ª–∞–≤—ã –º—ã —Ç–∞–∫–∂–µ –∑–∞–≥—Ä—É–∑–∏–º –≤ –Ω–∞—à—É –º–æ–¥–µ–ª—å –æ–±—â–µ–¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ –æ—Ç OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d319a0d",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/chapter-overview.webp\" width=1000px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9d4040",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model--0.webp\" width=1000px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debd79c3",
   "metadata": {},
   "source": [
    "# 4.1 –ú”ô—Ç—ñ–Ω  –º–æ–¥–µ–ª—å–¥–µ—Ä—ñ–Ω –±–∞“ì–∞–ª–∞—É\n",
    "# 4.1 –û—Ü–µ–Ω–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad32e79c",
   "metadata": {},
   "source": [
    "- –ë—ñ–∑ –±“±–ª –±”©–ª—ñ–º–¥–µ –∞–ª–¥—ã“£“ì—ã ”©—Ç–∫–µ–Ω—Ç–∞—Ä–∞—É–¥–∞ –ø–∞–π–¥–∞–ª–∞–Ω—ã–ª“ì–∞–Ω  GPT –º–æ–¥–µ–ª—ñ–Ω –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è–ª–∞—É –ø—Ä–æ—Ü–µ—Å—ã–Ω “õ—ã—Å“õ–∞—à–∞ “õ–∞–π—Ç–∞–ª–∞—É–¥–∞–Ω –±–∞—Å—Ç–∞–π–º—ã–∑.\n",
    "- –°–æ–¥–∞–Ω –∫–µ–π—ñ–Ω –±—ñ–∑ LLM-–¥–µ—Ä–≥–µ –∞—Ä–Ω–∞–ª“ì–∞–Ω –±–∞—Å—Ç–∞–ø“õ—ã –±–∞“ì–∞–ª–∞—É –º–µ—Ç—Ä–∏–∫–∞–ª–∞—Ä—ã–Ω —Ç–∞–ª“õ—ã–ª–∞–π–º—ã–∑.\n",
    "- –°–æ“£—ã–Ω–¥–∞, –æ—Å—ã –±”©–ª—ñ–º–¥–µ –±—ñ–∑ –±“±–ª –±–∞“ì–∞–ª–∞—É –º–µ—Ç—Ä–∏–∫–∞–ª–∞—Ä—ã–Ω –∂–∞—Ç—Ç—ã“õ—Ç—ã—Ä—É –∂”ô–Ω–µ –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–µ—Ä–µ–∫—Ç–µ—Ä –∂–∏—ã–Ω—ã–Ω–∞ “õ–æ–ª–¥–∞–Ω–∞–º—ã–∑.\n",
    "\n",
    "- –ú—ã –Ω–∞—á–∏–Ω–∞–µ–º —ç—Ç–æ—Ç —Ä–∞–∑–¥–µ–ª —Å –∫—Ä–∞—Ç–∫–æ–≥–æ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ GPT —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–æ–¥–∞ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≥–ª–∞–≤—ã.\n",
    "- –ó–∞—Ç–µ–º –º—ã –æ–±—Å—É–∂–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏ –¥–ª—è LLM.\n",
    "- –ù–∞–∫–æ–Ω–µ—Ü, –≤ —ç—Ç–æ–º —Ä–∞–∑–¥–µ–ª–µ –º—ã –ø—Ä–∏–º–µ–Ω–∏–º —ç—Ç–∏ –º–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏ –∫ –æ–±—É—á–∞—é—â–µ–º—É –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º—É –Ω–∞–±–æ—Ä–∞–º –¥–∞–Ω–Ω—ã—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87b58af",
   "metadata": {},
   "source": [
    "### 4.1.1 GPT –∞—Ä“õ—ã–ª—ã —Ç–µ–∫—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—è–ª–∞—É\n",
    "### 4.1.1 –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910b1650",
   "metadata": {},
   "source": [
    "- –ë—ñ–∑ –∞–ª–¥—ã“£“ì—ã —Ç–∞—Ä–∞—É–¥–∞“ì—ã –∫–æ–¥—Ç—ã “õ–æ–ª–¥–∞–Ω—ã–ø, GPT –º–æ–¥–µ–ª—ñ–Ω –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è–ª–∞–π–º—ã–∑\n",
    "- –ú—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å GPT, –∏—Å–ø–æ–ª—å–∑—É—è –∫–æ–¥ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≥–ª–∞–≤—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b8feef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9055de7f",
   "metadata": {},
   "source": [
    "1.  **–ë—ñ–∑ $0.1$ dropout “õ–æ–ª–¥–∞–Ω–∞–º—ã–∑, –±—ñ—Ä–∞“õ “õ–∞–∑—ñ—Ä–≥—ñ —É–∞“õ—ã—Ç—Ç–∞ LLM-–¥–µ—Ä–¥—ñ dropout “õ–æ–ª–¥–∞–Ω–±–∞–π –∂–∞—Ç—Ç—ã”©—Ç—ã—Ä—É –∂–∏—ñ –∫–µ–∑–¥–µ—Å–µ–¥—ñ.**\n",
    "2.  **–°–æ–Ω–¥–∞–π-–∞“õ, –∑–∞–º–∞–Ω–∞—É–∏ LLM-–¥–µ—Ä —Å“±—Ä–∞–Ω—ã—Å (query), –∫—ñ–ª—Ç (key) –∂”ô–Ω–µ –º”ô–Ω (value) –º–∞—Ç—Ä–∏—Ü–∞–ª–∞—Ä—ã “Ø—à—ñ–Ω `nn.Linear` “õ–∞–±–∞—Ç—Ç–∞—Ä—ã–Ω–¥–∞ —ã“ì—ã—Å—É (bias) –≤–µ–∫—Ç–æ—Ä–ª–∞—Ä—ã–Ω –ø–∞–π–¥–∞–ª–∞–Ω–±–∞–π–¥—ã (–±“±—Ä—ã–Ω“ì—ã GPT –º–æ–¥–µ–ª—å–¥–µ—Ä—ñ–Ω–µ–Ω –∞–π—ã—Ä–º–∞—à—ã–ª—ã“ì—ã), –±“±–ª `\"qkv_bias\": False` –æ—Ä–Ω–∞—Ç—É –∞—Ä“õ—ã–ª—ã –∂“Ø–∑–µ–≥–µ –∞—Å—ã—Ä—ã–ª–∞–¥—ã.**\n",
    "3.  **–ë—ñ–∑ –º–æ–¥–µ–ª—å–¥—ñ –æ“õ—ã—Ç—É “Ø—à—ñ–Ω –µ—Å–µ–ø—Ç–µ—É —Ä–µ—Å—É—Ä—Å—Ç–∞—Ä—ã–Ω—ã“£ —Ç–∞–ª–∞–ø—Ç–∞—Ä—ã–Ω –∞–∑–∞–π—Ç—É –º–∞“õ—Å–∞—Ç—ã–Ω–¥–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç “±–∑—ã–Ω–¥—ã“ì—ã–Ω (`context_length`) –±–∞—Ä –±–æ–ª“ì–∞–Ω—ã $256$ —Ç–æ–∫–µ–Ω–≥–µ –¥–µ–π—ñ–Ω “õ—ã—Å“õ–∞—Ä—Ç–∞–º—ã–∑, –∞–ª –±–∞—Å—Ç–∞–ø“õ—ã $124$ –º–∏–ª–ª–∏–æ–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä–ª—ñ GPT-$2$ –º–æ–¥–µ–ª—ñ $1024$ —Ç–æ–∫–µ–Ω–¥—ñ –ø–∞–π–¥–∞–ª–∞–Ω“ì–∞–Ω.**\n",
    "    - **–ë“±–ª –Ω–æ—É—Ç–±—É–∫—Ç–∞—Ä–¥–∞ –∫–æ–¥—Ç—ã –æ—Ä—ã–Ω–¥–∞–π –∞–ª—É “Ø—à—ñ–Ω –∂–∞—Å–∞–ª“ì–∞–Ω.**\n",
    "    - **–ê–ª–∞–π–¥–∞, `context_length`-—Ç—ñ $1024$ —Ç–æ–∫–µ–Ω–≥–µ –¥–µ–π—ñ–Ω –∞—Ä—Ç—Ç—ã—Ä–∞ –∞–ª—É“ì–∞ –±–æ–ª–∞–¥—ã (–±“±–ª –µ—à“õ–∞–Ω–¥–∞–π –∫–æ–¥ ”©–∑–≥–µ—Ä—ñ—Å—Ç–µ—Ä—ñ–Ω —Ç–∞–ª–∞–ø –µ—Ç–ø–µ–π–¥—ñ).**\n",
    "    - **–ë—ñ–∑ —Å–æ–Ω–¥–∞–π-–∞“õ –∫–µ–π—ñ–Ω—ñ—Ä–µ–∫ –∞–ª–¥—ã–Ω –∞–ª–∞ –æ“õ—ã—Ç—ã–ª“ì–∞–Ω —Å–∞–ª–º–∞“õ—Ç–∞—Ä–¥–∞–Ω $1024$ `context_length`-—ñ –±–∞—Ä –º–æ–¥–µ–ª—å–¥—ñ –∂“Ø–∫—Ç–µ–π—Ç—ñ–Ω –±–æ–ª–∞–º—ã–∑.**\n",
    "***\n",
    "1.  **–ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º dropout $0.1$ , –Ω–æ –≤ –Ω–∞—Å—Ç–æ—è—â–µ–µ –≤—Ä–µ–º—è –¥–æ–≤–æ–ª—å–Ω–æ —á–∞—Å—Ç–æ –æ–±—É—á–∞—é—Ç LLM –±–µ–∑ dropout.**\n",
    "2.  **–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ LLM —Ç–∞–∫–∂–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –≤–µ–∫—Ç–æ—Ä—ã —Å–º–µ—â–µ–Ω–∏—è (bias) –≤ —Å–ª–æ—è—Ö `nn.Linear` –¥–ª—è –º–∞—Ç—Ä–∏—Ü –∑–∞–ø—Ä–æ—Å–∞ (query), –∫–ª—é—á–∞ (key) –∏ –∑–Ω–∞—á–µ–Ω–∏—è (value) (–≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Ä–∞–Ω–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π GPT), —á—Ç–æ –¥–æ—Å—Ç–∏–≥–∞–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∫–æ–π `\"qkv_bias\": False`.**\n",
    "3.  **–ú—ã —É–º–µ–Ω—å—à–∞–µ–º –¥–ª–∏–Ω—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (`context_length`) –≤—Å–µ–≥–æ –¥–æ $256$ —Ç–æ–∫–µ–Ω–æ–≤, —á—Ç–æ–±—ã —Å–Ω–∏–∑–∏—Ç—å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–º —Ä–µ—Å—É—Ä—Å–∞–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏, —Ç–æ–≥–¥–∞ –∫–∞–∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å GPT-$2$ —Å $124$ –º–∏–ª–ª–∏–æ–Ω–∞–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞ $1024$ —Ç–æ–∫–µ–Ω–∞.**\n",
    "    - **–≠—Ç–æ —Å–¥–µ–ª–∞–Ω–æ –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã  –≤—ã–ø–æ–ª–Ω—è—Ç—å –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞ –Ω–∞ —Å–≤–æ–∏—Ö –Ω–æ—É—Ç–±—É–∫–∞—Ö.**\n",
    "    - **–û–¥–Ω–∞–∫–æ, –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å `context_length` –¥–æ $1024$ —Ç–æ–∫–µ–Ω–æ–≤ (—ç—Ç–æ –Ω–µ –ø–æ—Ç—Ä–µ–±—É–µ—Ç –Ω–∏–∫–∞–∫–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –∫–æ–¥–µ).**\n",
    "    - **–ú—ã —Ç–∞–∫–∂–µ –∑–∞–≥—Ä—É–∑–∏–º –º–æ–¥–µ–ª—å —Å `context_length` $1024$ –ø–æ–∑–∂–µ –∏–∑ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã—Ö –≤–µ—Å–æ–≤.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc8f90d",
   "metadata": {},
   "source": [
    "- –ú”ô—Ç—ñ–Ω –∂–∞—Å–∞—É “Ø—à—ñ–Ω –∞–ª–¥—ã“£“ì—ã —Ç–∞—Ä–∞—É–¥–∞“ì—ã `generate_text_simple` —Ñ—É–Ω–∫—Ü–∏—è—Å—ã–Ω “õ–æ–ª–¥–∞–Ω–∞–º—ã–∑.\n",
    "- –ë“±“ì–∞–Ω “õ–æ—Å–∞, –±—ñ–∑ –æ—Å—ã —Ç–∞—Ä–∞—É –±–æ–π—ã–Ω–¥–∞ “õ–æ–ª–¥–∞–Ω—ã–ª–∞—Ç—ã–Ω —Ç–æ–∫–µ–Ω –∂”ô–Ω–µ –º”ô—Ç—ñ–Ω “±—Å—ã–Ω—ã–º–¥–∞—Ä—ã –∞—Ä–∞—Å—ã–Ω–¥–∞ —Ç“Ø—Ä–ª–µ–Ω–¥—ñ—Ä—É “Ø—à—ñ–Ω –µ–∫—ñ —ã“£“ì–∞–π–ª—ã —Ñ—É–Ω–∫—Ü–∏—è–Ω—ã (`text_to_token_ids` –∂”ô–Ω–µ `token_ids_to_text`) “õ–æ–ª–¥–∞–Ω–∞–º—ã–∑.\n",
    "\n",
    "- –î–∞–ª–µ–µ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é `generate_text_simple` –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≥–ª–∞–≤—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞.\n",
    "- –ö—Ä–æ–º–µ —Ç–æ–≥–æ, –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–≤–µ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ (–∏–ª–∏ —É–¥–æ–±–Ω—ã–µ) —Ñ—É–Ω–∫—Ü–∏–∏ (`text_to_token_ids` –∏ `token_ids_to_text`) –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –º–µ–∂–¥—É —Ç–æ–∫–µ–Ω–∞–º–∏ –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ –≤—Å–µ–π —ç—Ç–æ–π –≥–ª–∞–≤—ã."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f2a2d7",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/gpt-process.webp\" width=1000px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f774c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnŸÖ refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae1dc4f",
   "metadata": {},
   "source": [
    "* –ñ–æ“ì–∞—Ä—ã–¥–∞ –∫”©—Ä—ñ–ø —Ç“±—Ä“ì–∞–Ω—ã–º—ã–∑–¥–∞–π, –º–æ–¥–µ–ª—å ”ô–ª—ñ –∂–∞—Ç—Ç—ã“õ–ø–∞“ì–∞–Ω–¥—ã“õ—Ç–∞–Ω –∂–∞“õ—Å—ã –º”ô—Ç—ñ–Ω —à—ã“ì–∞—Ä–∞ –∞–ª–º–∞–π–¥—ã.\n",
    "* –ö–µ–ª–µ—Å—ñ –±”©–ª—ñ–º–¥–µ –º–æ–¥–µ–ª—å–¥—ñ“£ —à—ã“ì–∞—Ä“ì–∞–Ω –Ω”ô—Ç–∏–∂–µ–ª–µ—Ä—ñ–Ω–µ –∞—Ä–Ω–∞–ª“ì–∞–Ω —à—ã“ì—ã–Ω (loss) –º–µ—Ç—Ä–∏–∫–∞—Å—ã–Ω –µ—Å–µ–ø—Ç–µ—É —Ç”ô—Å—ñ–ª–¥–µ—Ä—ñ–º–µ–Ω —Ç–∞–Ω—ã—Å–∞–º—ã–∑, –±“±–ª –∂–∞—Ç—Ç—ã“ì—É –±–∞—Ä—ã—Å—ã–Ω ”©–ª—à–µ—É–≥–µ –º“Ø–º–∫—ñ–Ω–¥—ñ–∫ –±–µ—Ä–µ–¥—ñ.\n",
    "* –ê–ª LLM –º–æ–¥–µ–ª—å–¥–µ—Ä—ñ–Ω –¥”ô–ª –±–∞–ø—Ç–∞—É (finetuning) —Ç—É—Ä–∞–ª—ã –∫–µ–ª–µ—Å—ñ —Ç–∞—Ä–∞—É–ª–∞—Ä–¥–∞ –º–æ–¥–µ–ª—å —Å–∞–ø–∞—Å—ã–Ω –±–∞“ì–∞–ª–∞—É–¥—ã“£ “õ–æ—Å—ã–º—à–∞ ”ô–¥—ñ—Å—Ç–µ—Ä—ñ –µ–Ω–≥—ñ–∑—ñ–ª–µ–¥—ñ.\n",
    "---\n",
    "* –ö–∞–∫ –º—ã –≤–∏–¥–∏–º –≤—ã—à–µ, –º–æ–¥–µ–ª—å –Ω–µ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ö–æ—Ä–æ—à–∏–π —Ç–µ–∫—Å—Ç, –ø–æ—Ç–æ–º—É —á—Ç–æ –æ–Ω–∞ –µ—â—ë –Ω–µ –æ–±—É—á–µ–Ω–∞.\n",
    "* –í —Å–ª–µ–¥—É—é—â–µ–º –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ –±—É–¥—É—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å (loss) –¥–ª—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è.\n",
    "* –í —Å–ª–µ–¥—É—é—â–∏—Ö –≥–ª–∞–≤–∞—Ö, –ø–æ—Å–≤—è—â—ë–Ω–Ω—ã—Ö –¥–æ–æ–±—É—á–µ–Ω–∏—é (finetuning) LLM, —Ç–∞–∫–∂–µ –±—É–¥—É—Ç —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e6b0e7",
   "metadata": {},
   "source": [
    "### 4.1.2 –ú”ô—Ç—ñ–Ω –≥–µ–Ω–µ—Ä–∞—Ü–∏—è—Å—ã–Ω—ã“£ —à—ã“ì—ã–Ω—ã–Ω (“õ–∞—Ç–µ—Å—ñ–Ω) –µ—Å–µ–ø—Ç–µ—É: –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è –∂”ô–Ω–µ perplexity (—à–∞—Ç–∞—Å—É)\n",
    "### 4.1.2 –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞: –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è –∏ perplexity (–∑–∞—Ç—Ä—É–¥–Ω–µ–Ω–∏–µ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93035f47",
   "metadata": {},
   "source": [
    "* –ê–π—Ç–∞–ª—ã“õ, –±—ñ–∑–¥–µ 2 –∂–∞—Ç—Ç—ã“ì—É –º—ã—Å–∞–ª—ã–Ω–∞ (“õ–∞—Ç–∞—Ä“ì–∞) –∞—Ä–Ω–∞–ª“ì–∞–Ω —Ç–æ–∫–µ–Ω ID-–ª–µ—Ä—ñ–Ω “õ–∞–º—Ç–∏—Ç—ã–Ω `inputs` —Ç–µ–Ω–∑–æ—Ä—ã –±–∞—Ä.\n",
    "* `inputs` –º”ô–Ω–¥–µ—Ä—ñ–Ω–µ —Å”ô–π–∫–µ—Å, `targets` —Ç–µ–Ω–∑–æ—Ä—ã –º–æ–¥–µ–ª—å–¥—ñ“£ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è–ª–∞—É—ã–Ω “õ–∞–ª–∞“ì–∞–Ω —Ç–æ–∫–µ–Ω ID-–ª–µ—Ä—ñ–Ω “õ–∞–º—Ç–∏–¥—ã.\n",
    "* –ù–∞–∑–∞—Ä –∞—É–¥–∞—Ä—ã“£—ã–∑, `targets` ‚Äî –±“±–ª `inputs` —Ç–µ–Ω–∑–æ—Ä—ã–Ω—ã“£ 1 –ø–æ–∑–∏—Ü–∏—è“ì–∞ —ã“ì—ã—Å—Ç—ã—Ä—ã–ª“ì–∞–Ω –Ω“±—Å“õ–∞—Å—ã (2-—Ç–∞—Ä–∞—É–¥–∞ –¥–µ—Ä–µ–∫—Ç–µ—Ä –∂“Ø–∫—Ç–µ—É—à—ñ–Ω—ñ –∂“Ø–∑–µ–≥–µ –∞—Å—ã—Ä“ì–∞–Ω–¥–∞ —Ç“Ø—Å—ñ–Ω–¥—ñ—Ä—ñ–ª–≥–µ–Ω–¥–µ–π).\n",
    "---\n",
    "* –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —É –Ω–∞—Å –µ—Å—Ç—å —Ç–µ–Ω–∑–æ—Ä `inputs`, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –¥–≤—É—Ö –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ (—Å—Ç—Ä–æ–∫).\n",
    "* –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ `inputs`, —Ç–µ–Ω–∑–æ—Ä `targets` —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–∫–µ–Ω-–∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å.\n",
    "* –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ `targets` ‚Äî —ç—Ç–æ –≤–µ—Ä—Å–∏—è `inputs`, —Å–¥–≤–∏–Ω—É—Ç–∞—è –Ω–∞ –æ–¥–Ω—É –ø–æ–∑–∏—Ü–∏—é, –∫–∞–∫ –æ–±—ä—è—Å–Ω—è–ª–æ—Å—å –≤ –≥–ª–∞–≤–µ 2 –ø—Ä–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66acd162",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39282c91",
   "metadata": {},
   "source": [
    "* `inputs` —Ç–µ–Ω–∑–æ—Ä—ã–Ω –º–æ–¥–µ–ª—å–≥–µ –±–µ—Ä–≥–µ–Ω –∫–µ–∑–¥–µ, ”ô—Ä“õ–∞–π—Å—ã—Å—ã–Ω–¥–∞ 3 —Ç–æ–∫–µ–Ω –±–∞—Ä—ã 2 –∫—ñ—Ä—ñ—Å –º—ã—Å–∞–ª—ã “Ø—à—ñ–Ω –ª–æ–≥–∏—Ç—Ç–µ—Ä –≤–µ–∫—Ç–æ—Ä—ã–Ω –∞–ª–∞–º—ã–∑.\n",
    "* ”ò—Ä–±—ñ—Ä —Ç–æ–∫–µ–Ω —Å”©–∑–¥—ñ–∫ ”©–ª—à–µ–º—ñ–Ω–µ —Å”ô–π–∫–µ—Å –∫–µ–ª–µ—Ç—ñ–Ω 50,257 ”©–ª—à–µ–º–¥—ñ –≤–µ–∫—Ç–æ—Ä –±–æ–ª—ã–ø —Ç–∞–±—ã–ª–∞–¥—ã.\n",
    "* `Softmax` —Ñ—É–Ω–∫—Ü–∏—è—Å—ã–Ω “õ–æ–ª–¥–∞–Ω—É –∞—Ä“õ—ã–ª—ã –ª–æ–≥–∏—Ç—Ç–µ—Ä —Ç–µ–Ω–∑–æ—Ä—ã–Ω —Å–æ–ª ”©–ª—à–µ–º–¥–µ–≥—ñ —ã“õ—Ç–∏–º–∞–ª–¥—ã“õ –º”ô–Ω–¥–µ—Ä—ñ–Ω “õ–∞–º—Ç–∏—Ç—ã–Ω —Ç–µ–Ω–∑–æ—Ä“ì–∞ –∞–π–Ω–∞–ª–¥—ã—Ä–∞ –∞–ª–∞–º—ã–∑.\n",
    "---\n",
    "* –ü–µ—Ä–µ–¥–∞–≤–∞—è —Ç–µ–Ω–∑–æ—Ä `inputs` –≤ –º–æ–¥–µ–ª—å, –º—ã –ø–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä –ª–æ–≥–∏—Ç–æ–≤ –¥–ª—è –¥–≤—É—Ö –≤—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤, –∫–∞–∂–¥—ã–π –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ —Ç—Ä—ë—Ö —Ç–æ–∫–µ–Ω–æ–≤.\n",
    "* –ö–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –≤–µ–∫—Ç–æ—Ä —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é 50 257, —á—Ç–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ä–∞–∑–º–µ—Ä—É —Å–ª–æ–≤–∞—Ä—è.\n",
    "* –ü—Ä–∏–º–µ–Ω—è—è —Ñ—É–Ω–∫—Ü–∏—é `softmax`, –º–æ–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Ç–µ–Ω–∑–æ—Ä –ª–æ–≥–∏—Ç–æ–≤ –≤ —Ç–µ–Ω–∑–æ—Ä —Ç–æ–π –∂–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a29cec17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553b86ea",
   "metadata": {},
   "source": [
    "* –¢”©–º–µ–Ω–¥–µ–≥—ñ —Å—É—Ä–µ—Ç—Ç–µ, –º—ã—Å–∞–ª —Ä–µ—Ç—ñ–Ω–¥–µ ”©—Ç–µ –∫—ñ—à–∫–µ–Ω—Ç–∞–π —Å”©–∑–¥—ñ–∫ “õ–æ–ª–¥–∞–Ω—ã–ø, —ã“õ—Ç–∏–º–∞–ª–¥—ã“õ –º”ô–Ω–¥–µ—Ä—ñ–Ω “õ–∞–π—Ç–∞–¥–∞–Ω –º”ô—Ç—ñ–Ω–≥–µ —Ç“Ø—Ä–ª–µ–Ω–¥—ñ—Ä—É –ø—Ä–æ—Ü–µ—Å—ñ –∫”©—Ä—Å–µ—Ç—ñ–ª–≥–µ–Ω. –ë“±–ª —Ç–∞“õ—ã—Ä—ã–ø—Ç—ã –±—ñ–∑ –∞–ª–¥—ã“£“ì—ã —Ç–∞—Ä–∞—É–¥—ã“£ —Å–æ“£—ã–Ω–¥–∞ —Ç–∞–ª“õ—ã–ª–∞“ì–∞–Ω–±—ã–∑.\n",
    "---\n",
    "* –ù–∞ —Ä–∏—Å—É–Ω–∫–µ –Ω–∏–∂–µ, —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ—á–µ–Ω—å –Ω–µ–±–æ–ª—å—à–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏, –ø–æ–∫–∞–∑–∞–Ω–æ, –∫–∞–∫ –º—ã –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ç–µ–∫—Å—Ç ‚Äî –æ–± —ç—Ç–æ–º –º—ã –≥–æ–≤–æ—Ä–∏–ª–∏ –≤ –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≥–ª–∞–≤—ã.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785fd181",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/proba-to-text.webp\" width=1000px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9491f0f0",
   "metadata": {},
   "source": [
    "* –ê–ª–¥—ã“£“ì—ã —Ç–∞—Ä–∞—É–¥–∞ —Ç–∞–ª“õ—ã–ª–∞–Ω“ì–∞–Ω–¥–∞–π, —ã“õ—Ç–∏–º–∞–ª–¥—ã“õ –º”ô–Ω–¥–µ—Ä—ñ–Ω –±–æ–ª–∂–∞“ì–∞–Ω —Ç–æ–∫–µ–Ω ID-–ª–µ—Ä—ñ–Ω–µ —Ç“Ø—Ä–ª–µ–Ω–¥—ñ—Ä—É “Ø—à—ñ–Ω `argmax` —Ñ—É–Ω–∫—Ü–∏—è—Å—ã–Ω “õ–æ–ª–¥–∞–Ω—É“ì–∞ –±–æ–ª–∞–¥—ã.\n",
    "* –ñ–æ“ì–∞—Ä—ã–¥–∞“ì—ã softmax —Ñ—É–Ω–∫—Ü–∏—è—Å—ã ”ô—Ä —Ç–æ–∫–µ–Ω “Ø—à—ñ–Ω 50,257 ”©–ª—à–µ–º–¥—ñ –≤–µ–∫—Ç–æ—Ä —à—ã“ì–∞—Ä–¥—ã; –∞–ª `argmax` —Ñ—É–Ω–∫—Ü–∏—è—Å—ã –æ—Å—ã –≤–µ–∫—Ç–æ—Ä–¥–∞“ì—ã –µ“£ –∂–æ“ì–∞—Ä—ã —ã“õ—Ç–∏–º–∞–ª–¥—ã“õ –º”ô–Ω—ñ–Ω—ñ“£ –æ—Ä–Ω—ã–Ω “õ–∞–π—Ç–∞—Ä–∞–¥—ã ‚Äî –±“±–ª –±–µ—Ä—ñ–ª–≥–µ–Ω —Ç–æ–∫–µ–Ω “Ø—à—ñ–Ω –±–æ–ª–∂–∞–Ω“ì–∞–Ω —Ç–æ–∫–µ–Ω ID –±–æ–ª—ã–ø —Ç–∞–±—ã–ª–∞–¥—ã.\n",
    "---\n",
    "* –ö–∞–∫ –æ–±—Å—É–∂–¥–∞–ª–æ—Å—å –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≥–ª–∞–≤–µ, –º—ã –º–æ–∂–µ–º –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é `argmax`, —á—Ç–æ–±—ã –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —Ç–æ–∫–µ–Ω–æ–≤.\n",
    "* –§—É–Ω–∫—Ü–∏—è softmax –≤—ã—à–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∞ –≤–µ–∫—Ç–æ—Ä —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é 50 257 –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞; —Ñ—É–Ω–∫—Ü–∏—è `argmax` –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–∑–∏—Ü–∏—é —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤ —ç—Ç–æ–º –≤–µ–∫—Ç–æ—Ä–µ ‚Äî —ç—Ç–æ –∏ –µ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–æ–∫–µ–Ω–∞ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dcb33d",
   "metadata": {},
   "source": [
    "* –ë—ñ–∑–¥–µ ”ô—Ä“õ–∞–π—Å—ã—Å—ã–Ω–¥–∞ 3 —Ç–æ–∫–µ–Ω –±–∞—Ä 2 –∫—ñ—Ä—ñ—Å –ø–∞—Ä—Ç–∏—è (batch) –±–æ–ª“ì–∞–Ω–¥—ã“õ—Ç–∞–Ω, –Ω”ô—Ç–∏–∂–µ—Å—ñ–Ω–¥–µ 2√ó3 –±–æ–ª–∂–∞–Ω“ì–∞–Ω —Ç–æ–∫–µ–Ω ID-–ª–µ—Ä—ñ–Ω –∞–ª–∞–º—ã–∑:\n",
    "---\n",
    "* –ü–æ—Å–∫–æ–ª—å–∫—É —É –Ω–∞—Å –µ—Å—Ç—å 2 –≤—Ö–æ–¥–Ω—ã—Ö –±–∞—Ç—á–∞, –∫–∞–∂–¥—ã–π –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ 3 —Ç–æ–∫–µ–Ω–∞, –º—ã –ø–æ–ª—É—á–∞–µ–º 2√ó3 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Ç–æ–∫–µ–Ω–æ–≤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f5b395b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8573abb5",
   "metadata": {},
   "source": [
    "* –ï–≥–µ—Ä –±—ñ–∑ –æ—Å—ã —Ç–æ–∫–µ–Ω–¥–µ—Ä–¥—ñ –¥–µ–∫–æ–¥—Ç–∞—Å–∞“õ, –æ–ª–∞—Ä–¥—ã“£ –º–æ–¥–µ–ª—å–¥–µ–Ω –∫“Ø—Ç–∫–µ–Ω, —è“ì–Ω–∏ –º–∞“õ—Å–∞—Ç—Ç—ã —Ç–æ–∫–µ–Ω–¥–µ—Ä–¥–µ–Ω –∞–π—Ç–∞—Ä–ª—ã“õ—Ç–∞–π ”©–∑–≥–µ—à–µ –µ–∫–µ–Ω—ñ–Ω –∫”©—Ä–µ–º—ñ–∑:\n",
    "---\n",
    "* –ï—Å–ª–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–∏ —Ç–æ–∫–µ–Ω—ã, –º—ã —É–≤–∏–¥–∏–º, —á—Ç–æ –æ–Ω–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç —Ç–µ—Ö —Ç–æ–∫–µ–Ω–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º—ã —Ö–æ—Ç–∏–º, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∞ ‚Äî —Ç–æ –µ—Å—Ç—å –æ—Ç —Ü–µ–ª–µ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3019b66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde20821",
   "metadata": {},
   "source": [
    "* –ë“±–ª –º–æ–¥–µ–ª—å ”ô–ª—ñ –∂–∞—Ç—Ç—ã“õ–ø–∞“ì–∞–Ω–¥—ã“õ—Ç–∞–Ω –±–æ–ª—ã–ø —Ç“±—Ä.\n",
    "* –ú–æ–¥–µ–ª—å–¥—ñ –∂–∞—Ç—Ç—ã“õ—Ç—ã—Ä—É “Ø—à—ñ–Ω –æ–Ω—ã“£ –¥“±—Ä—ã—Å –±–æ–ª–∂–∞–º–¥–∞—Ä–¥–∞–Ω (–º–∞“õ—Å–∞—Ç—Ç–∞—Ä–¥–∞–Ω) “õ–∞–Ω—à–∞–ª—ã“õ—Ç—ã –∞–ª—ã—Å –µ–∫–µ–Ω—ñ–Ω –±—ñ–ª—É—ñ–º—ñ–∑ “õ–∞–∂–µ—Ç.\n",
    "---\n",
    "* –≠—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–æ—Ç–æ–º—É, —á—Ç–æ –º–æ–¥–µ–ª—å –µ—â—ë –Ω–µ –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞.\n",
    "* –ß—Ç–æ–±—ã –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å, –Ω–∞–º –Ω—É–∂–Ω–æ –∑–Ω–∞—Ç—å, –Ω–∞—Å–∫–æ–ª—å–∫–æ –µ—ë –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö (—Ü–µ–ª–µ–≤—ã—Ö) –∑–Ω–∞—á–µ–Ω–∏–π."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d616b4c",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/proba-index.webp\" width=1000px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0eb2ff94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability shape: torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Probability shape: {probas.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2d00fe",
   "metadata": {},
   "source": [
    "* `2` - –º”ô—Ç—ñ–Ω “Ø–ª–≥—ñ–ª–µ—Ä —Å–∞–Ω—ã   \n",
    "* `3` - –º”ô—Ç—ñ–Ω–¥–µ–≥—ñ —Å”©–∑–¥–µ—Ä —Å–∞–Ω—ã   \n",
    "* `50257` - —Å”©–∑–¥—ñ–∫ ”©–ª—à–µ–º—ñ   \n",
    "***\n",
    "* `2` - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ —Ç–µ–∫—Å—Ç–∞   \n",
    "* `3` - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ –∫–∞–∂–¥–æ–º —Ç–µ–∫—Å—Ç–µ  \n",
    "* `50257` - —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Å–ª–æ–≤–∞—Ä—è  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49c440c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct target tokens  for first text: [3626, 6100, 345]\n",
      "Correct target tokens  for second text: [1107, 588, 11311]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Correct target tokens  for first text: {targets[0].tolist()}\")\n",
    "print(f\"Correct target tokens  for second text: {targets[1].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54c6cfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], [3626, 6100, 345]] # \"effort moves you\"\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], [1107,  588, 11311]] # \"really like chocolate\"\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d903828",
   "metadata": {},
   "source": [
    "- –ë—ñ–∑ –æ—Å—ã –º”ô–Ω–¥–µ—Ä–¥—ñ“£ –±–∞—Ä–ª—ã“ì—ã–Ω –±–∞—Ä—ã–Ω—à–∞ –∞—Ä—Ç—Ç—ã—Ä—ã–ø, –æ–ª–∞—Ä–¥—ã 1 —ã“õ—Ç–∏–º–∞–ª–¥—ã“ì—ã–Ω–∞ –∂–∞“õ—ã–Ω–¥–∞—Ç“õ—ã–º—ã–∑ –∫–µ–ª–µ–¥—ñ.\n",
    "- –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞–ª—ã“õ –æ“£—Ç–∞–π–ª–∞–Ω–¥—ã—Ä—É–¥–∞ **—ã“õ—Ç–∏–º–∞–ª–¥—ã“õ –±–∞–ª–ª–¥–∞—Ä–¥—ã“£** –ª–æ–≥–∞—Ä–∏—Ñ–º—ã–Ω –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—è–ª–∞—É —ã“õ—Ç–∏–º–∞–ª–¥—ã“õ –±–∞–ª–ª–¥—ã“£ ”©–∑—ñ–Ω –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—è–ª–∞—É“ì–∞ “õ–∞—Ä–∞“ì–∞–Ω–¥–∞ –æ“£–∞–π—ã—Ä–∞“õ.\n",
    "---\n",
    "- –ú—ã —Ö–æ—Ç–∏–º –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ —ç—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏—è, –ø—Ä–∏–±–ª–∏–∂–∞—è –∏—Ö –∫ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏, —Ä–∞–≤–Ω–æ–π 1.\n",
    "- –í –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ª–æ–≥–∞—Ä–∏—Ñ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ª–µ–≥—á–µ, —á–µ–º —Å–∞–º—É –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e052abdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# Compute logarithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d8ed2a",
   "metadata": {},
   "source": [
    "- –°–æ—Å—ã–Ω –±—ñ–∑ –æ—Ä—Ç–∞—à–∞ –ª–æ–≥–∞—Ä–∏—Ñ–º–¥—ñ–∫ —ã“õ—Ç–∏–º–∞–ª–¥—ã“õ—Ç—ã –µ—Å–µ–ø—Ç–µ–π–º—ñ–∑\n",
    "- –î–∞–ª–µ–µ –º—ã –≤—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–π –ª–æ–≥–∞—Ä–∏—Ñ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52d55fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd2d4b2",
   "metadata": {},
   "source": [
    "* –ë–∞—Å—Ç—ã –º–∞“õ—Å–∞—Ç ‚Äì –º–æ–¥–µ–ª—å —Å–∞–ª–º–∞“õ—Ç–∞—Ä—ã–Ω –æ“£—Ç–∞–π–ª–∞–Ω–¥—ã—Ä—É –∞—Ä“õ—ã–ª—ã –æ—Å—ã –æ—Ä—Ç–∞—à–∞ –ª–æ–≥–∞—Ä–∏—Ñ–º–¥—ñ–∫ —ã“õ—Ç–∏–º–∞–ª–¥—ã“õ—Ç—ã –º“Ø–º–∫—ñ–Ω–¥—ñ–≥—ñ–Ω—à–µ “Ø–ª–∫–µ–Ω –µ—Ç—É.\n",
    "* –õ–æ–≥–∞—Ä–∏—Ñ–º–≥–µ –±–∞–π–ª–∞–Ω—ã—Å—Ç—ã, –µ“£ “Ø–ª–∫–µ–Ω –º“Ø–º–∫—ñ–Ω –º”ô–Ω $0$-–≥–µ —Ç–µ“£, –∞–ª –±—ñ–∑ “õ–∞–∑—ñ—Ä $0$-–¥–µ–Ω –∞–ª—ã—Å–ø—ã–∑.\n",
    "***\n",
    "* –¶–µ–ª—å ‚Äî —Å–¥–µ–ª–∞—Ç—å —ç—Ç—É —Å—Ä–µ–¥–Ω—é—é –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–∞–∫ –º–æ–∂–Ω–æ –±–æ–ª—å—à–µ–π (–∏–ª–∏: *–º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å*) –ø—É—Ç–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏.\n",
    "* –ò–∑-–∑–∞ –ª–æ–≥–∞—Ä–∏—Ñ–º–∞, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –≤–æ–∑–º–æ–∂–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ä–∞–≤–Ω–æ $0$, –∏ –º—ã –≤ –Ω–∞—Å—Ç–æ—è—â–µ–µ –≤—Ä–µ–º—è –¥–∞–ª–µ–∫–∏ –æ—Ç $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee364f6",
   "metadata": {},
   "source": [
    "* –¢–µ—Ä–µ“£ –æ“õ—ã—Ç—É–¥–∞ –æ—Ä—Ç–∞—à–∞ –ª–æ–≥–∞—Ä–∏—Ñ–º–¥—ñ–∫ —ã“õ—Ç–∏–º–∞–ª–¥—ã“õ—Ç—ã –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—è–ª–∞—É–¥—ã“£ –æ—Ä–Ω—ã–Ω–∞, –æ–Ω—ã“£ *—Ç–µ—Ä—ñ—Å* –º”ô–Ω—ñ–Ω –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è–ª–∞—É “õ–∞–±—ã–ª–¥–∞–Ω“ì–∞–Ω; –±—ñ–∑–¥—ñ“£ –∂–∞“ì–¥–∞–π–¥–∞ $-10.7722$ –º”ô–Ω—ñ–Ω $0$-–≥–µ –∂–∞“õ—ã–Ω–¥–∞—Ç—É “Ø—à—ñ–Ω –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—è–ª–∞—É–¥—ã“£ –æ—Ä–Ω—ã–Ω–∞, —Ç–µ—Ä–µ“£ –æ“õ—ã—Ç—É–¥–∞ –±—ñ–∑ $10.7722$ –º”ô–Ω—ñ–Ω $0$-–≥–µ –∂–∞“õ—ã–Ω–¥–∞—Ç—É “Ø—à—ñ–Ω –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è–ª–∞–π–º—ã–∑.\n",
    "* $-10.7722$-–≥–µ “õ–∞—Ä–∞–º–∞-“õ–∞—Ä—Å—ã –º”ô–Ω, —è“ì–Ω–∏ $10.7722$, —Ç–µ—Ä–µ“£ –æ“õ—ã—Ç—É–¥–∞ **“õ–∏—ã–ª—ã—Å–ø–∞–ª—ã —ç–Ω—Ç—Ä–æ–ø–∏—è —à—ã“ì—ã–Ω—ã** (cross-entropy loss) –¥–µ–ø —Ç–µ –∞—Ç–∞–ª–∞–¥—ã.\n",
    "***\n",
    "* –í –≥–ª—É–±–æ–∫–æ–º –æ–±—É—á–µ–Ω–∏–∏ –≤–º–µ—Å—Ç–æ –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏–∏ —Å—Ä–µ–¥–Ω–µ–π –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∏–Ω—è—Ç–æ –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –µ–µ *–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ* –∑–Ω–∞—á–µ–Ω–∏–µ; –≤ –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ, –≤–º–µ—Å—Ç–æ –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏–∏ $-10.7722$, —á—Ç–æ–±—ã –æ–Ω–æ –ø—Ä–∏–±–ª–∏–∂–∞–ª–æ—Å—å –∫ $0$, –≤ –≥–ª—É–±–æ–∫–æ–º –æ–±—É—á–µ–Ω–∏–∏ –º—ã –±—ã –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–ª–∏ $10.7722$, —á—Ç–æ–±—ã –æ–Ω–æ –ø—Ä–∏–±–ª–∏–∂–∞–ª–æ—Å—å –∫ $0$.\n",
    "* –ó–Ω–∞—á–µ–Ω–∏–µ, –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω–æ–µ $-10.7722$, —Ç–æ –µ—Å—Ç—å $10.7722$, –≤ –≥–ª—É–±–æ–∫–æ–º –æ–±—É—á–µ–Ω–∏–∏ —Ç–∞–∫–∂–µ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è **–ø–æ—Ç–µ—Ä–µ–π –ø–µ—Ä–µ–∫—Ä–µ—Å—Ç–Ω–æ–π —ç–Ω—Ç—Ä–æ–ø–∏–∏** (cross-entropy loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "736655fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e4fed2",
   "metadata": {},
   "source": [
    "* PyTorch-—Ç–∞ –∞–ª–¥—ã“£“ì—ã “õ–∞–¥–∞–º–¥–∞—Ä–¥—ã –æ—Ä—ã–Ω–¥–∞–π—Ç—ã–Ω `cross_entropy` —Ñ—É–Ω–∫—Ü–∏—è—Å—ã –∂“Ø–∑–µ–≥–µ –∞—Å—ã—Ä—ã–ª“ì–∞–Ω.\n",
    "***\n",
    "* –í PyTorch —É–∂–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è `cross_entropy`, –∫–æ—Ç–æ—Ä–∞—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —à–∞–≥–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a718a6ab",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/cross-entropy.webp?123\" width=1000px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d17eea2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a59305c",
   "metadata": {},
   "source": [
    "* PyTorch-—Ç–∞“ì—ã `cross_entropy` —Ñ—É–Ω–∫—Ü–∏—è—Å—ã “Ø—à—ñ–Ω –±—ñ–∑ –±“±–ª —Ç–µ–Ω–∑–æ—Ä–ª–∞—Ä–¥—ã **–±–∞—Ç—á ”©–ª—à–µ–º—ñ (batch dimension) –±–æ–π—ã–Ω—à–∞ –±—ñ—Ä—ñ–∫—Ç—ñ—Ä—É –∞—Ä“õ—ã–ª—ã** **–∂–∞–∑—ã“õ—Ç–∞—É—ã–º—ã–∑** (—Ç–µ–≥—ñ—Å—Ç–µ—É—ñ–º—ñ–∑) –∫–µ—Ä–µ–∫:\n",
    "***\n",
    "* –î–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ `cross_entropy` –≤ PyTorch –º—ã —Ö–æ—Ç–∏–º **'–≤—ã–ø—Ä—è–º–∏—Ç—å' (—Å–≥–ª–∞–¥–∏—Ç—å)** —ç—Ç–∏ —Ç–µ–Ω–∑–æ—Ä—ã, –æ–±—ä–µ–¥–∏–Ω–∏–≤ –∏—Ö –ø–æ **—Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –±–∞—Ç—á–∞** (batch dimension):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15599b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b794ec",
   "metadata": {},
   "source": [
    "* `Target` ‚Äî –±“±–ª —Ç–æ–∫–µ–Ω –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–ª–∞—Ä—ã, –æ–ª–∞—Ä —Å–æ–Ω–¥–∞–π-–∞“õ –ª–æ–≥–∏—Ç—Ç–µ—Ä–¥–µ–≥—ñ –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—è–ª–∞“ì—ã–º—ã–∑ (1-–≥–µ) –∫–µ–ª–µ—Ç—ñ–Ω –∏–Ω–¥–µ–∫—Å—Ç—ñ–∫ –ø–æ–∑–∏—Ü–∏—è–ª–∞—Ä–¥—ã –±—ñ–ª–¥—ñ—Ä–µ–¥—ñ.\n",
    "* PyTorch-—Ç–∞“ì—ã `cross_entropy` —Ñ—É–Ω–∫—Ü–∏—è—Å—ã softmax –∂”ô–Ω–µ –ª–æ–≥–∞—Ä–∏—Ñ–º–¥—ñ–∫ —ã“õ—Ç–∏–º–∞–ª–¥—ã“õ—Ç—ã –µ—Å–µ–ø—Ç–µ—É –ø—Ä–æ—Ü–µ—Å—Ç–µ—Ä—ñ–Ω –∞–≤—Ç–æ–º–∞—Ç—Ç—ã —Ç“Ø—Ä–¥–µ –æ—Ä—ã–Ω–¥–∞–π–¥—ã, —è“ì–Ω–∏ –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—è–ª–∞–Ω—É—ã —Ç–∏—ñ—Å –ª–æ–≥–∏—Ç—Ç–µ—Ä–¥–µ–≥—ñ —Ç–æ–∫–µ–Ω –∏–Ω–¥–µ–∫—Å—Ç–µ—Ä—ñ –±–æ–π—ã–Ω—à–∞ —ñ—à–∫—ñ –µ—Å–µ–ø—Ç–µ—É–ª–µ—Ä–¥—ñ ”©–∑—ñ –∞—Ç“õ–∞—Ä–∞–¥—ã.\n",
    "---\n",
    "* `Target` ‚Äî —ç—Ç–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —Ç–æ–∫–µ–Ω–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —Ç–∞–∫–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç –∏–Ω–¥–µ–∫—Å–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –≤ –ª–æ–≥–∏—Ç–∞—Ö, –∫–æ—Ç–æ—Ä—ã–µ –º—ã —Ö–æ—Ç–∏–º –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å.\n",
    "* –§—É–Ω–∫—Ü–∏—è `cross_entropy` –≤ PyTorch –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ softmax –∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è —Ç–µ—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –ª–æ–≥–∏—Ç–∞—Ö, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c5e8d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac7485d",
   "metadata": {},
   "source": [
    "- Perplexity (—à–∞—Ç–∞—Å—É) - LLM-–Ω—ñ“£  cross-entropy —à—ã“ì—ã–Ω—ã–Ω—ã“£ –¥”ô—Ä–µ–∂–µ–ª—ñ–∫ –∫”©—Ä—Å–µ—Ç–∫—ñ—à—ñ\n",
    "- Perplexity (–∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ) - —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ç–∞ –æ—Ç –ø–æ—Ç–µ—Ä—å –ø–æ –ø–µ—Ä–µ–∫—Ä—ë—Å—Ç–Ω–æ–π —ç–Ω—Ç—Ä–æ–ø–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e9de506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0411533c",
   "metadata": {},
   "source": [
    "* Perplexity –∫”©–±—ñ–Ω–µ —Ç“Ø—Å—ñ–Ω—É–≥–µ –∂–µ“£—ñ–ª –∫”©—Ä—Å–µ—Ç–∫—ñ—à —Ä–µ—Ç—ñ–Ω–¥–µ “õ–∞—Ä–∞—Å—Ç—ã—Ä—ã–ª–∞–¥—ã, —Å–µ–±–µ–±—ñ –æ–Ω—ã –º–æ–¥–µ–ª—å ”ô—Ä “õ–∞–¥–∞–º–¥–∞ —Å–µ–Ω—ñ–º—Å—ñ–∑ –±–æ–ª–∞—Ç—ã–Ω ¬´—Å”©–∑–¥–µ—Ä –∫”©–ª–µ–º—ñ¬ª —Ä–µ—Ç—ñ–Ω–¥–µ —Ç“Ø—Å—ñ–Ω–¥—ñ—Ä—É–≥–µ –±–æ–ª–∞–¥—ã (–∂–æ“ì–∞—Ä—ã–¥–∞“ì—ã –º—ã—Å–∞–ª–¥–∞ –±“±–ª 48 725 —Å”©–∑ –Ω–µ–º–µ—Å–µ —Ç–æ–∫–µ–Ω).\n",
    "* –ë–∞—Å“õ–∞—à–∞ –∞–π—Ç“õ–∞–Ω–¥–∞, perplexity –º–æ–¥–µ–ª—å –±–æ–ª–∂–∞“ì–∞–Ω —ã“õ—Ç–∏–º–∞–ª–¥—ã“õ—Ç–∞—Ä —Ç–∞—Ä–∞–ª—É—ã  –Ω–∞“õ—Ç—ã —Å”©–∑–¥–µ—Ä–¥—ñ“£ —Ç–∞—Ä–∞–ª—É—ã–Ω–∞ “õ–∞–Ω—à–∞–ª—ã“õ—Ç—ã –∂–∞“õ—ã–Ω –µ–∫–µ–Ω—ñ–Ω –∫”©—Ä—Å–µ—Ç–µ—Ç—ñ–Ω ”©–ª—à–µ–º.\n",
    "* –®—ã“ì—ã–Ω (loss) —Å–∏—è“õ—Ç—ã, perplexity –Ω–µ“ì“±—Ä–ª—ã–º —Ç”©–º–µ–Ω –±–æ–ª—Å–∞ ‚Äî –º–æ–¥–µ–ª—å–¥—ñ“£ –±–æ–ª–∂–∞–º–¥–∞—Ä—ã –Ω–∞“õ—Ç—ã —Ç–∞—Ä–∞–ª—É“ì–∞ —Å–æ“ì“±—Ä–ª—ã–º –∂–∞“õ—ã–Ω –¥–µ–≥–µ–Ω–¥—ñ –±—ñ–ª–¥—ñ—Ä–µ–¥—ñ.\n",
    "---\n",
    "* Perplexity —á–∞—Å—Ç–æ —Å—á–∏—Ç–∞–µ—Ç—Å—è –±–æ–ª–µ–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã–º –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–º, –ø–æ—Ç–æ–º—É —á—Ç–æ –µ—ë –º–æ–∂–Ω–æ –ø–æ–Ω–∏–º–∞—Ç—å –∫–∞–∫ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è, –≤ –∫–æ—Ç–æ—Ä–æ–º –º–æ–¥–µ–ª—å –∏—Å–ø—ã—Ç—ã–≤–∞–µ—Ç –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç—å –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ (–≤ –ø—Ä–∏–≤–µ–¥—ë–Ω–Ω–æ–º –≤—ã—à–µ –ø—Ä–∏–º–µ—Ä–µ —ç—Ç–æ 48 725 —Å–ª–æ–≤ –∏–ª–∏ —Ç–æ–∫–µ–Ω–æ–≤).\n",
    "* –ò–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏, –ø–µ—Ä–ø–ª–µ–∫—Å–∏—è –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ –º–æ–¥–µ–ª—å—é, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é —Å–ª–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ.\n",
    "* –ü–æ–¥–æ–±–Ω–æ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å, –±–æ–ª–µ–µ –Ω–∏–∑–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–µ—Ä–ø–ª–µ–∫—Å–∏–∏ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –±–ª–∏–∂–µ –∫ —Ä–µ–∞–ª—å–Ω–æ–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5e3cff",
   "metadata": {},
   "source": [
    "### “ö–∞—Ä–∞–ø–∞–π—ã–º –º—ã—Å–∞–ª\n",
    "\n",
    "–ú–æ–¥–µ–ª—å –∫–µ–ª–µ—Å—ñ —Å”©–π–ª–µ–º–¥—ñ –∂–∞–ª“ì–∞—Å—Ç—ã—Ä—É“ì–∞ —Ç—ã—Ä—ã—Å—ã–ø –∂–∞—Ç—ã—Ä –¥–µ–ª—ñ–∫:\n",
    "\n",
    "> ‚ÄúI love eating  ...‚Äù\n",
    "\n",
    "–ú“Ø–º–∫—ñ–Ω –∫–µ–ª–µ—Å—ñ —Å”©–∑–¥–µ—Ä:\n",
    "`[\"apples\", \"cars\", \"books\", \"tables\"]`\n",
    "\n",
    "* –ï–≥–µ—Ä –º–æ–¥–µ–ª—å **\"apples\"** —Å”©–∑—ñ–Ω **80%** —ã“õ—Ç–∏–º–∞–ª–¥—ã“õ–ø–µ–Ω –¥“±—Ä—ã—Å –¥–µ–ø —Å–∞–Ω–∞—Å–∞ ‚Äî\n",
    "  ‚Üí –º–æ–¥–µ–ª—å **—Å–µ–Ω—ñ–º–¥—ñ** ‚Üí **—Ç”©–º–µ–Ω perplexity**\n",
    "\n",
    "* –ï–≥–µ—Ä –±–∞—Ä–ª—ã“õ 4 —Å”©–∑–≥–µ **25%** —ã“õ—Ç–∏–º–∞–ª–¥—ã“õ –±–µ—Ä—Å–µ ‚Äî\n",
    "  ‚Üí –º–æ–¥–µ–ª—å **—à–∞—Ç–∞—Å“õ–∞–Ω** ‚Üí **–∂–æ“ì–∞—Ä—ã perplexity**\n",
    "---\n",
    "### –ú–∞“ì—ã–Ω–∞—Å—ã\n",
    "\n",
    "**Perplexity** —à–∞–º–∞–º–µ–Ω –±—ã–ª–∞–π —Ç“Ø—Å—ñ–Ω–¥—ñ—Ä—ñ–ª–µ–¥—ñ:\n",
    "\n",
    "> ‚Äú–ú–æ–¥–µ–ª—å “õ–∞–Ω—à–∞ –Ω“±—Å“õ–∞–Ω—ã –±—ñ—Ä–¥–µ–π –¥“±—Ä—ã—Å –¥–µ–ø —à–∞—Ç–∞—Å—Ç—ã—Ä—ã–ø —Ç“±—Ä.‚Äù\n",
    "\n",
    "–°–æ–Ω–¥—ã“õ—Ç–∞–Ω:\n",
    "\n",
    "* Perplexity ‚âà 1 ‚Üí –º–æ–¥–µ–ª—å ”©—Ç–µ —Å–µ–Ω—ñ–º–¥—ñ (–±—ñ—Ä “ì–∞–Ω–∞ –¥“±—Ä—ã—Å –Ω“±—Å“õ–∞ –±–∞—Ä).\n",
    "* Perplexity ‚âà 10 ‚Üí –º–æ–¥–µ–ª—å 10 –Ω“±—Å“õ–∞–Ω—ã“£ –±—ñ—Ä—ñ–Ω —Ç–∞“£–¥–∞—É“ì–∞ “õ–∏–Ω–∞–ª—ã–ø —Ç“±—Ä.\n",
    "---\n",
    "### “ö—ã—Å“õ–∞—à–∞:\n",
    "\n",
    "* **Cross-entropy loss** ‚Üí –ú–æ–¥–µ–ª—å “õ–∞–Ω—à–∞–ª—ã“õ—Ç—ã “õ–∞—Ç–µ–ª–µ—Å–∫–µ–Ω—ñ–Ω –∫”©—Ä—Å–µ—Ç–µ–¥—ñ.\n",
    "* **Perplexity** ‚Üí –ú–æ–¥–µ–ª—å “õ–∞–Ω—à–∞ –Ω“±—Å“õ–∞–Ω—ã“£ –∞—Ä–∞—Å—ã–Ω–∞–Ω —Ç–∞“£–¥–∞–π –∞–ª–º–∞–π —Ç“±—Ä“ì–∞–Ω—ã–Ω –∫”©—Ä—Å–µ—Ç–µ–¥—ñ.\n",
    "* **–¢”©–º–µ–Ω perplexity** ‚Üí –∂–∞“õ—Å—ã –º–æ–¥–µ–ª—å –¥–µ–≥–µ–Ω —Å”©–∑.\n",
    "---\n",
    "### –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–º–µ—Ä\n",
    "\n",
    "–ú–æ–¥–µ–ª—å –ø—ã—Ç–∞–µ—Ç—Å—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ:\n",
    "\n",
    "> ‚ÄúI love eating  ...‚Äù\n",
    "\n",
    "–í–æ–∑–º–æ–∂–Ω—ã–µ —Å–ª–æ–≤–∞:\n",
    "`[\"apples\", \"cars\", \"books\", \"tables\"]`\n",
    "\n",
    "* –ï—Å–ª–∏ –º–æ–¥–µ–ª—å —Å—á–∏—Ç–∞–µ—Ç **\"apples\"** –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é **80%** ‚Äî\n",
    "  ‚Üí –º–æ–¥–µ–ª—å **—É–≤–µ—Ä–µ–Ω–∞** ‚Üí **–Ω–∏–∑–∫–∞—è –ø–µ—Ä–ø–ª–µ–∫—Å–∏—è**\n",
    "\n",
    "* –ï—Å–ª–∏ –æ–Ω–∞ –¥–∞—ë—Ç –≤—Å–µ–º –ø–æ **25%** ‚Äî\n",
    "  ‚Üí –º–æ–¥–µ–ª—å **–≤ –∑–∞–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–µ** ‚Üí **–≤—ã—Å–æ–∫–∞—è –ø–µ—Ä–ø–ª–µ–∫—Å–∏—è**\n",
    "---\n",
    "### –°–º—ã—Å–ª\n",
    "\n",
    "**–ü–µ—Ä–ø–ª–µ–∫—Å–∏—è** –ø—Ä–∏–º–µ—Ä–Ω–æ –æ–∑–Ω–∞—á–∞–µ—Ç:\n",
    "\n",
    "> ‚Äú–°–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –º–æ–¥–µ–ª—å —Å—á–∏—Ç–∞–µ—Ç –æ–¥–∏–Ω–∞–∫–æ–≤–æ –≤–æ–∑–º–æ–∂–Ω—ã–º–∏.‚Äù\n",
    "\n",
    "–ü–æ—ç—Ç–æ–º—É:\n",
    "\n",
    "* Perplexity ‚âà 1 ‚Üí –º–æ–¥–µ–ª—å –æ—á–µ–Ω—å —É–≤–µ—Ä–µ–Ω–∞ (—Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç).\n",
    "* Perplexity ‚âà 10 ‚Üí –º–æ–¥–µ–ª—å –∑–∞–ø—É—Ç–∞–ª–∞—Å—å –º–µ–∂–¥—É 10 –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏.\n",
    "---\n",
    "### üßæ –ö–æ—Ä–æ—Ç–∫–æ:\n",
    "\n",
    "* **Cross-entropy loss** ‚Üí –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª—å –æ—à–∏–±–∞–µ—Ç—Å—è.\n",
    "* **Perplexity** ‚Üí –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª—å –∑–∞–ø—É—Ç–∞–Ω–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ —Å–ª–æ–≤–∞.\n",
    "* **–ú–µ–Ω—å—à–µ perplexity** ‚Üí –∑–Ω–∞—á–∏—Ç, –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –ª—É—á—à–µ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab0f9b5",
   "metadata": {},
   "source": [
    "### 4.1.3 –ñ–∞—Ç—Ç—ã“õ—Ç—ã—Ä—É –∂”ô–Ω–µ –≤–∞–ª–∏–¥–∞—Ü–∏—è –∂–∏—ã–Ω–¥–∞—Ä—ã–Ω—ã“£ —à—ã“ì—ã–Ω–¥–∞—Ä—ã–Ω –µ—Å–µ–ø—Ç–µ—É\n",
    "### 4.1.3 –†–∞—Å—á–µ—Ç –ø–æ—Ç–µ—Ä—å –Ω–∞ –æ–±—É—á–∞—é—â–µ–º –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–∞—Ö\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35249404",
   "metadata": {},
   "source": [
    "- –ë—ñ–∑ LLM-–¥—ñ –æ“õ—ã—Ç—É “Ø—à—ñ–Ω —Å–∞–ª—ã—Å—Ç—ã—Ä–º–∞–ª—ã —Ç“Ø—Ä–¥–µ —à–∞“ì—ã–Ω –¥–µ—Ä–µ–∫—Ç–µ—Ä –∂–∏–Ω–∞“ì—ã–Ω –ø–∞–π–¥–∞–ª–∞–Ω–∞–º—ã–∑ (—ñ—Å –∂“Ø–∑—ñ–Ω–¥–µ, —Ç–µ–∫ –±—ñ—Ä —à—ã“ì–∞—Ä–º–∞).\n",
    "* –°–µ–±–µ–ø—Ç–µ—Ä—ñ:\n",
    "    - –°—ñ–∑ –∫–æ–¥ –º—ã—Å–∞–ª–¥–∞—Ä—ã–Ω “õ–æ–ª–∞–π–ª—ã GPU-—Å—ã–∑ –Ω–æ—É—Ç–±—É–∫ –∫–æ–º–ø—å—é—Ç–µ—Ä–¥–µ –±—ñ—Ä–Ω–µ—à–µ –º–∏–Ω—É—Ç —ñ—à—ñ–Ω–¥–µ —ñ—Å–∫–µ “õ–æ—Å–∞ –∞–ª–∞—Å—ã–∑\n",
    "    - –û“õ—ã—Ç—É —Å–∞–ª—ã—Å—Ç—ã—Ä–º–∞–ª—ã —Ç“Ø—Ä–¥–µ —Ç–µ–∑ –∞—è“õ—Ç–∞–ª–∞–¥—ã (–∞–ø—Ç–∞–ª–∞—Ä –µ–º–µ—Å, –º–∏–Ω—É—Ç—Ç–∞—Ä), –±“±–ª –±—ñ–ª—ñ–º –±–µ—Ä—É –º–∞“õ—Å–∞—Ç—Ç–∞—Ä—ã “Ø—à—ñ–Ω –∂–∞“õ—Å—ã\n",
    "    - –ë—ñ–∑ “õ–æ“ì–∞–º–¥—ã“õ “õ–æ–ª–¥–∞–Ω—ã—Å—Ç–∞“ì—ã –º”ô—Ç—ñ–Ω–¥—ñ –ø–∞–π–¥–∞–ª–∞–Ω–∞–º—ã–∑, –æ–Ω—ã –ø–∞–π–¥–∞–ª–∞–Ω—É “õ“±“õ—ã“õ—Ç–∞—Ä—ã–Ω –±“±–∑–±–∞–π  “õ–æ–ª–¥–∞–Ω—É“ì–∞ –±–æ–ª–∞–¥—ã\n",
    "\n",
    "- –ú—ã—Å–∞–ª—ã, Llama 2 7B –º–æ–¥–µ–ª—ñ–Ω 2 —Ç—Ä–∏–ª–ª–∏–æ–Ω —Ç–æ–∫–µ–Ω–¥–µ –∂–∞—Ç—Ç—ã“õ—Ç—ã—Ä—É “Ø—à—ñ–Ω A100 GPU-–ª–∞—Ä–¥–∞ 184 320 GPU —Å–∞“ì–∞—Ç—ã “õ–∞–∂–µ—Ç –±–æ–ª–¥—ã\n",
    "\n",
    "- –û—Å—ã —É–∞“õ—ã—Ç—Ç–∞ AWS-—Ç–µ–≥—ñ 8xA100 –±“±–ª—Ç—Ç—ã“õ —Å–µ—Ä–≤–µ—Ä—ñ–Ω—ñ“£ —Å–∞“ì–∞—Ç—Ç—ã“õ “õ“±–Ω—ã —à–∞–º–∞–º–µ–Ω 30 –¥–æ–ª–ª–∞—Ä–¥—ã “õ“±—Ä–∞–π–¥—ã\n",
    "- –°–æ–Ω—ã–º–µ–Ω, —à–∞–º–∞–º–µ–Ω –µ—Å–µ–ø—Ç–µ—É –±–æ–π—ã–Ω—à–∞, –æ—Å—ã LLM-–¥—ñ –æ“õ—ã—Ç—É “õ“±–Ω—ã $184 320 / 8 \\times 30$ = $690 000$ –¥–æ–ª–ª–∞—Ä –±–æ–ª–∞—Ä –µ–¥—ñ.\n",
    "---\n",
    "- –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –Ω–µ–±–æ–ª—å—à–æ–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è LLL (—Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏, —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ).\n",
    "* –ü—Ä–∏—á–∏–Ω—ã:\n",
    "    - –í—ã –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞ –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç –Ω–∞ –Ω–æ—É—Ç–±—É–∫–µ –±–µ–∑ –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ GPU\n",
    "    - –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–∞–µ—Ç—Å—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –±—ã—Å—Ç—Ä–æ (–º–∏–Ω—É—Ç—ã –≤–º–µ—Å—Ç–æ –Ω–µ–¥–µ–ª—å), —á—Ç–æ —Ö–æ—Ä–æ—à–æ –¥–ª—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ü–µ–ª–µ–π\n",
    "    - –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –¥–æ—Å—Ç–æ—è–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ –≤–∫–ª—é—á–∏—Ç—å –≤ —ç—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –±–µ–∑ –Ω–∞—Ä—É—à–µ–Ω–∏—è –∫–∞–∫–∏—Ö-–ª–∏–±–æ –ø—Ä–∞–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.\n",
    "- –ù–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è –æ–±—É—á–µ–Ω–∏—è Llama 2 7B –Ω–∞ 2 —Ç—Ä–∏–ª–ª–∏–æ–Ω–∞—Ö —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ—Ç—Ä–µ–±–æ–≤–∞–ª–æ—Å—å 184 320 GPU-—á–∞—Å–æ–≤ –Ω–∞ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞—Ö A100.\n",
    "- –ù–∞ –º–æ–º–µ–Ω—Ç –Ω–∞–ø–∏—Å–∞–Ω–∏—è —Å—Ç–∞—Ç—å–∏ –ø–æ—á–∞—Å–æ–≤–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –æ–±–ª–∞—á–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞ 8xA100 –Ω–∞ AWS —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ 30 –¥–æ–ª–ª–∞—Ä–æ–≤ –°–®–ê\n",
    "- –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –ø–æ –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–º —Ä–∞—Å—á–µ—Ç–∞–º, –æ–±—É—á–µ–Ω–∏–µ —ç—Ç–æ–π –ë–Ø–ú —Å—Ç–æ–∏–ª–æ –±—ã $184 320 / 8 \\times 30$ = $690 000$ –¥–æ–ª–ª–∞—Ä–æ–≤ –°–®–ê."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8efc101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"time_machine.txt\"\n",
    "url = (\"https://raw.githubusercontent.com/Azamat0315277/LLM_from_scratch/refs/heads/main/ch01/time_machine.txt\")\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67354d0",
   "metadata": {},
   "source": [
    "- –ú”ô—Ç—ñ–Ω–Ω—ñ“£ –¥“±—Ä—ã—Å –∂“Ø–∫—Ç–µ–ª–≥–µ–Ω—ñ–Ω —Ç–µ–∫—Å–µ—Ä—É “Ø—à—ñ–Ω –∞–ª“ì–∞—à“õ—ã –∂”ô–Ω–µ —Å–æ“£“ì—ã 99 —Ç–∞“£–±–∞–Ω—ã —à—ã“ì–∞—Ä—É\n",
    "- –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–≥–æ, —á—Ç–æ —Ç–µ–∫—Å—Ç –∑–∞–≥—Ä—É–∂–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ, –ø—É—Ç–µ–º –≤—ã–≤–æ–¥–∞ –ø–µ—Ä–≤—ã—Ö –∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 99 —Å–∏–º–≤–æ–ª–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99ccc4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I.\n",
      " Introduction\n",
      "\n",
      "\n",
      "The Time Traveller (for so it will be convenient to speak of him) was\n",
      "expoundin\n"
     ]
    }
   ],
   "source": [
    "# First 99 characters\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0267cea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "help produce our new eBooks, and how to\n",
      "subscribe to our email newsletter to hear about new eBooks.\n"
     ]
    }
   ],
   "source": [
    "# Last 99 characters\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7602f9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 197730\n",
      "Tokens: 49509\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dea93e",
   "metadata": {},
   "source": [
    "- 49509 —Ç–æ–∫–µ–Ω —Å–∞–Ω—ã LLM-–¥—ñ “Ø–π—Ä–µ—Ç—É “Ø—à—ñ–Ω ”©—Ç–µ “õ—ã—Å“õ–∞, –±—ñ—Ä–∞“õ –±“±–ª —É–π—Ä–µ–Ω—É –º–∞“õ—Å–∞—Ç—ã–Ω–¥–∞ (–±—ñ–∑ –∫–µ–π—ñ–Ω—ñ—Ä–µ–∫ –∞–ª–¥—ã–Ω –∞–ª–∞ “Ø–π—Ä–µ—Ç—ñ–ª–≥–µ–Ω —Å–∞–ª–º–∞“õ—Ç–∞—Ä–¥—ã –¥–∞ –∂“Ø–∫—Ç–µ–π–º—ñ–∑)\n",
    "- –° 5,145 —Ç–æ–∫–µ–Ω–∞–º–∏ —Ç–µ–∫—Å—Ç –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è LLM, –Ω–æ —ç—Ç–æ –≤ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ü–µ–ª—è—Ö (–º—ã —Ç–∞–∫–∂–µ –∑–∞–≥—Ä—É–∑–∏–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ –ø–æ–∑–∂–µ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d348051",
   "metadata": {},
   "source": [
    "- –ö–µ–ª–µ—Å—ñ –±–æ–ª—ã–ø, –±—ñ–∑ –¥–µ—Ä–µ–∫—Ç–µ—Ä –∂–∏—ã–Ω—ã–Ω –∂–∞—Ç—Ç—ã“õ—Ç—ã—Ä—É –∂”ô–Ω–µ –≤–∞–ª–∏–¥–∞—Ü–∏—è –∂–∏—ã–Ω—ã–Ω–∞ –±”©–ª–µ–º—ñ–∑ –∂”ô–Ω–µ LLM –∂–∞—Ç—Ç—ã“õ—Ç—ã—Ä—É “Ø—à—ñ–Ω –ø–∞–∫–µ—Ç—Ç–µ—Ä–¥—ñ –¥–∞–π—ã–Ω–¥–∞—É –º–∞“õ—Å–∞—Ç—ã–Ω–¥–∞ –¥–µ—Ä–µ–∫—Ç–µ—Ä –∂“Ø–∫—Ç–µ—É—à—ñ–ª–µ—Ä—ñ–Ω “õ–æ–ª–¥–∞–Ω–∞–º—ã–∑.\n",
    "- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è–ª–∞—É –º–∞“õ—Å–∞—Ç—ã–Ω–¥–∞ —Ç”©–º–µ–Ω–¥–µ–≥—ñ —Å—É—Ä–µ—Ç `max_length=6` –¥–µ–ø “õ–∞–±—ã–ª–¥–∞–Ω–∞–¥—ã, –±—ñ—Ä–∞“õ –æ“õ—ã—Ç—É –∂“Ø–∫—Ç–µ—É—à—ñ—Å—ñ “Ø—à—ñ–Ω –±—ñ–∑ `max_length`‚Äë—Ç—ã LLM‚Äë–Ω—ñ“£ “õ–æ–ª–¥–∞–π—Ç—ã–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç “±–∑—ã–Ω–¥—ã“ì—ã–Ω–∞ —Ç–µ“£ –µ—Ç—ñ–ø –æ—Ä–Ω–∞—Ç–∞–º—ã–∑.\n",
    "- –¢”©–º–µ–Ω–¥–µ–≥—ñ —Å—É—Ä–µ—Ç —Ç–µ–∫ –∫—ñ—Ä—ñ—Å —Ç–æ–∫–µ–Ω–¥–µ—Ä—ñ–Ω “õ–∞—Ä–∞–ø–∞–π—ã–º–¥—ã–ª—ã“õ “Ø—à—ñ–Ω –∫”©—Ä—Å–µ—Ç–µ–¥—ñ.\n",
    "- –ë—ñ–∑ LLM‚Äë–¥—ñ –º”ô—Ç—ñ–Ω–¥–µ–≥—ñ –∫–µ–ª–µ—Å—ñ —Å”©–∑–¥—ñ –±–æ–ª–∂–∞—É“ì–∞ “Ø–π—Ä–µ—Ç–µ—Ç—ñ–Ω–¥—ñ–∫—Ç–µ–Ω, –º–∞“õ—Å–∞—Ç—Ç–∞—Ä (targets) –æ—Å—ã –∫—ñ—Ä—ñ—Å—Ç–µ—Ä–≥–µ “±“õ—Å–∞—Å, –±—ñ—Ä–∞“õ –±—ñ—Ä –ø–æ–∑–∏—Ü–∏—è“ì–∞ –∂—ã–ª–∂—ã—Ç—ã–ª“ì–∞–Ω.\n",
    "***\n",
    "- –î–∞–ª–µ–µ –º—ã –¥–µ–ª–∏–º –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ–±—É—á–∞—é—â–∏–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä—ã –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥—Ä—É–∑—á–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –ø–∞–∫–µ—Ç–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è LLM.\n",
    "- –î–ª—è —Ü–µ–ª–µ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–∞ —Ä–∏—Å—É–Ω–∫–µ –Ω–∏–∂–µ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è `max_length=6`, –Ω–æ –¥–ª—è –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º—ã —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º `max_length`, —Ä–∞–≤–Ω—ã–π –¥–ª–∏–Ω–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–π LLM.\n",
    "- –ù–∞ —Ä–∏—Å—É–Ω–∫–µ –Ω–∏–∂–µ –ø–æ–∫–∞–∑–∞–Ω—ã —Ç–æ–ª—å–∫–æ –≤—Ö–æ–¥–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è.\n",
    "- –ü–æ—Å–∫–æ–ª—å–∫—É –º—ã –æ–±—É—á–∞–µ–º LLM –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–µ–µ —Å–ª–æ–≤–æ –≤ —Ç–µ–∫—Å—Ç–µ, —Ü–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (targets) –≤—ã–≥–ª—è–¥—è—Ç —Ç–∞–∫ –∂–µ, –∫–∞–∫ –∏ –≤—Ö–æ–¥–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã, –∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º —Ç–æ–≥–æ, —á—Ç–æ –æ–Ω–∏ —Å–¥–≤–∏–Ω—É—Ç—ã –Ω–∞ –æ–¥–Ω—É –ø–æ–∑–∏—Ü–∏—é."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0e41e5",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/batching.webp\" width=1000px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a3307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5147f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c292d36",
   "metadata": {},
   "source": [
    "- –ë—ñ–∑ –µ—Å–µ–ø—Ç–µ—É —Ä–µ—Å—É—Ä—Å—Ç–∞—Ä—ã–Ω–∞ –¥–µ–≥–µ–Ω —Å“±—Ä–∞–Ω—ã—Å—Ç—ã –∞–∑–∞–π—Ç—É “Ø—à—ñ–Ω –∂”ô–Ω–µ –¥–µ—Ä–µ–∫—Ç–µ—Ä –∂–∏—ã–Ω—ã–Ω—ã“£ ”©–∑—ñ –∫—ñ—à–∫–µ–Ω—Ç–∞–π –±–æ–ª“ì–∞–Ω–¥—ã“õ—Ç–∞–Ω —Å–∞–ª—ã—Å—Ç—ã—Ä–º–∞–ª—ã —Ç“Ø—Ä–¥–µ –∫—ñ—à–∫–µ–Ω—Ç–∞–π –±–∞—Ç—á ”©–ª—à–µ–º—ñ–Ω “õ–æ–ª–¥–∞–Ω–∞–º—ã–∑.\n",
    "- –ú—ã—Å–∞–ª—ã, Llama 2 7B –±–∞—Ç—á ”©–ª—à–µ–º—ñ 1024‚Äë–ø–µ–Ω –æ“õ—ã—Ç—ã–ª–¥—ã.\n",
    "***\n",
    "- –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –Ω–µ–±–æ–ª—å—à–æ–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—áa, —á—Ç–æ–±—ã —Å–Ω–∏–∑–∏—Ç—å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–º —Ä–µ—Å—É—Ä—Å–∞–º, –∞ —Ç–∞–∫–∂–µ –ø–æ—Ç–æ–º—É, —á—Ç–æ —Å–∞–º –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ –æ—á–µ–Ω—å –º–∞–ª.\n",
    "- –ù–∞–ø—Ä–∏–º–µ—Ä, Llama 2 7B –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞ —Å —Ä–∞–∑–º–µ—Ä–æ–º –±–∞—Ç—áa 1024."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3795d0",
   "metadata": {},
   "source": [
    "* –î–µ—Ä–µ–∫—Ç–µ—Ä–¥—ñ“£ –¥“±—Ä—ã—Å –∂“Ø–∫—Ç–µ–ª–≥–µ–Ω—ñ–Ω —Ç–µ–∫—Å–µ—Ä—É–≥–µ –∞—Ä–Ω–∞–ª“ì–∞–Ω “õ–æ—Å—ã–º—à–∞ —Ç–µ–∫—Å–µ—Ä—ñ—Å (–º—ñ–Ω–¥–µ—Ç—Ç—ñ –µ–º–µ—Å):\n",
    "* –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è) –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–≥–æ, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b3c13e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00233afa",
   "metadata": {},
   "source": [
    "* –¢–∞“ì—ã –±—ñ—Ä “õ–æ—Å—ã–º—à–∞ —Ç–µ–∫—Å–µ—Ä—ñ—Å ‚Äî —Ç–æ–∫–µ–Ω ”©–ª—à–µ–º–¥–µ—Ä—ñ–Ω—ñ“£ –∫“Ø—Ç—ñ–ª–µ—Ç—ñ–Ω –¥–∏–∞–ø–∞–∑–æ–Ω–¥–∞ –µ–∫–µ–Ω—ñ–Ω —Ç–µ–∫—Å–µ—Ä—É:\n",
    "* –ï—â—ë –æ–¥–Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ ‚Äî —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ä–∞–∑–º–µ—Ä—ã —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –æ–∂–∏–¥–∞–µ–º–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a3c62df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 44544\n",
      "Validation tokens: 4608\n",
      "All tokens: 49152\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4675dd82",
   "metadata": {},
   "source": [
    "* –ö–µ–ª–µ—Å—ñ “õ–∞–¥–∞–º–¥–∞ –±–µ—Ä—ñ–ª–≥–µ–Ω –±–∞—Ç—á “Ø—à—ñ–Ω cross-entropy —à—ã“ì—ã–Ω—ã–Ω (loss) –µ—Å–µ–ø—Ç–µ–π—Ç—ñ–Ω –∫”©–º–µ–∫—à—ñ —Ñ—É–Ω–∫—Ü–∏—è–Ω—ã —ñ—Å–∫–µ –∞—Å—ã—Ä–∞–º—ã–∑.\n",
    "* –°–æ–Ω—ã–º–µ–Ω “õ–∞—Ç–∞—Ä, –¥–µ—Ä–µ–∫—Ç–µ—Ä –∂“Ø–∫—Ç–µ—É—à—ñ—Å—ñ–Ω–¥–µ (data loader)  –±–µ–ª–≥—ñ–ª–µ–Ω–≥–µ–Ω –±–∞—Ç—á—Ç–∞—Ä —Å–∞–Ω—ã –±–æ–π—ã–Ω—à–∞ —à—ã“ì—ã–Ω–¥—ã –µ—Å–µ–ø—Ç–µ–π—Ç—ñ–Ω –µ–∫—ñ–Ω—à—ñ –∫”©–º–µ–∫—à—ñ —Ñ—É–Ω–∫—Ü–∏—è–Ω—ã “õ“±—Ä–∞–º—ã–∑.\n",
    "---\n",
    "* –î–∞–ª–µ–µ –º—ã —Ä–µ–∞–ª–∏–∑—É–µ–º –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è cross-entropy –ø–æ—Ç–µ—Ä—å (loss) –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –±–∞—Ç—á–∞.\n",
    "* –ö—Ä–æ–º–µ —Ç–æ–≥–æ, –º—ã —Ä–µ–∞–ª–∏–∑—É–µ–º –≤—Ç–æ—Ä—É—é –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –≤—ã—á–∏—Å–ª—è–µ—Ç –ø–æ—Ç–µ—Ä–∏ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –±–∞—Ç—á–µ–π –≤ –∑–∞–≥—Ä—É–∑—á–∏–∫–µ –¥–∞–Ω–Ω—ã—Ö (data loader)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e18d7468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8e043b",
   "metadata": {},
   "source": [
    "* –ï–≥–µ—Ä —Å—ñ–∑–¥–µ CUDA “õ–æ–ª–¥–∞–π—Ç—ã–Ω GPU –±–∞—Ä –∫–æ–º–ø—å—é—Ç–µ—Ä –±–æ–ª—Å–∞, –∫–æ–¥“õ–∞ –µ—à“õ–∞–Ω–¥–∞–π ”©–∑–≥–µ—Ä—ñ—Å –µ–Ω–≥—ñ–∑–±–µ–π-–∞“õ LLM –º–æ–¥–µ–ª—å GPU-–¥–µ –æ“õ—ã—Ç—ã–ª–∞–¥—ã.\n",
    "* `device` –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ –∞—Ä“õ—ã–ª—ã –¥–µ—Ä–µ–∫—Ç–µ—Ä–¥—ñ“£ LLM –º–æ–¥–µ–ª—ñ–Ω—ñ“£ –æ—Ä–Ω–∞–ª–∞—Å“õ–∞–Ω “õ“±—Ä—ã–ª“ì—ã—Å—ã–º–µ–Ω –±—ñ—Ä “õ“±—Ä—ã–ª“ì—ã–¥–∞ –∂“Ø–∫—Ç–µ–ª—É—ñ–Ω “õ–∞–º—Ç–∞–º–∞—Å—ã–∑ –µ—Ç–µ–º—ñ–∑.\n",
    "---\n",
    "* –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å GPU —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA, LLM –±—É–¥–µ—Ç –æ–±—É—á–∞—Ç—å—Å—è –Ω–∞ GPU –±–µ–∑ –∫–∞–∫–∏—Ö-–ª–∏–±–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –∫–æ–¥–µ.\n",
    "* –° –ø–æ–º–æ—â—å—é –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ `device` –º—ã –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –Ω–∞ —Ç–æ –∂–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ, –≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –º–æ–¥–µ–ª—å LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7237f304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device.\n",
      "Training loss: 10.984251044262415\n",
      "Validation loss: 10.96391593085395\n"
     ]
    }
   ],
   "source": [
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebafc1d",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-1.webp\" width=1000px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf260418",
   "metadata": {},
   "source": [
    "## 4.2 LLM –∂–∞—Ç—Ç—ã“õ—Ç—ã—Ä—É\n",
    "## 4.2 –û–±—É—á–µ–Ω–∏–µ LLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdee906",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/train-steps.webp\" width=1000px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fce6c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139dea55",
   "metadata": {},
   "source": [
    "* –ï–Ω–¥—ñ  –æ“õ—ã—Ç—É —Ñ—É–Ω–∫—Ü–∏—è—Å—ã–Ω –ø–∞–π–¥–∞–ª–∞–Ω—ã–ø, LLM –º–æ–¥–µ–ª—ñ–Ω –∂–∞—Ç—Ç—ã”©—Ç—ã—Ä–∞–π—ã“õ:\n",
    "* –¢–µ–ø–µ—Ä—å –æ–±—É—á–∏–º LLM, –∏—Å–ø–æ–ª—å–∑—É—è –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –æ–±—É—á–µ–Ω–∏—è:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0086eb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"The Medical Man got\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "# end_time = time.time()\n",
    "# execution_time_minutes = (end_time - start_time) / 60\n",
    "# print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10e02e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc50943",
   "metadata": {},
   "source": [
    "* –ñ–æ“ì–∞—Ä—ã–¥–∞“ì—ã –Ω”ô—Ç–∏–∂–µ–ª–µ—Ä–≥–µ “õ–∞—Ä–∞–ø, –º–æ–¥–µ–ª—å –±–∞—Å—Ç–∞–ø“õ—ã–¥–∞ —Ç“Ø—Å—ñ–Ω—ñ–∫—Å—ñ–∑ —Å”©–∑ —Ç—ñ–∑–±–µ–∫—Ç–µ—Ä—ñ–Ω —Ç—É–¥—ã—Ä–∞—Ç—ã–Ω—ã–Ω, –∞–ª —Å–æ“£—ã–Ω–∞ “õ–∞—Ä–∞–π –≥—Ä–∞–º–º–∞—Ç–∏–∫–∞–ª—ã“õ —Ç“±—Ä“ì—ã–¥–∞–Ω –¥“±—Ä—ã—Å —Å”©–π–ª–µ–º–¥–µ—Ä —à—ã“ì–∞—Ä–∞ –∞–ª–∞—Ç—ã–Ω—ã–Ω –∫”©—Ä–µ–º—ñ–∑.\n",
    "* –ê–ª–∞–π–¥–∞, —Ç—Ä–µ–Ω–∏–Ω–≥ –∂”ô–Ω–µ –≤–∞–ª–∏–¥–∞—Ü–∏—è –∂–∏—ã–Ω—Ç—ã“õ—Ç–∞—Ä—ã–Ω–¥–∞“ì—ã —à—ã“ì—ã–Ω –º”ô–Ω–¥–µ—Ä—ñ–Ω–µ —Å“Ø–π–µ–Ω—Å–µ–∫, –º–æ–¥–µ–ª—å —à–∞–º–∞–¥–∞–Ω —Ç—ã—Å “Ø–π—Ä–µ–Ω–µ –±–∞—Å—Ç–∞“ì–∞–Ω—ã–Ω –±–∞–π“õ–∞–π–º—ã–∑.\n",
    "* –ï–≥–µ—Ä —Å–æ“£—ã–Ω–¥–∞ –æ–ª –∂–∞–∑“ì–∞–Ω –±—ñ—Ä–Ω–µ—à–µ “Ø–∑—ñ–Ω–¥—ñ–Ω—ñ —Ç–µ–∫—Å–µ—Ä—Å–µ–∫, –æ–ª–∞—Ä–¥—ã“£ —Ç—Ä–µ–Ω–∏–Ω–≥ –∂–∏—ã–Ω—Ç—ã“ì—ã–Ω–¥–∞ –¥”ô–ª–º–µ-–¥”ô–ª –±–∞—Ä –µ–∫–µ–Ω—ñ–Ω —Ç–∞–±–∞–º—ã–∑ ‚Äî —è“ì–Ω–∏ –æ–ª –¥–µ—Ä–µ–∫—Ç–µ—Ä–¥—ñ –∂–∞—Ç—Ç–∞–ø –∞–ª“ì–∞–Ω.\n",
    "* –ö–µ–π—ñ–Ω –±—ñ–∑ –±“±–ª –∂–∞—Ç—Ç–∞–ø –∞–ª—É–¥—ã –±–µ–ª–≥—ñ–ª—ñ –±—ñ—Ä –¥–µ“£–≥–µ–π–¥–µ –∞–∑–∞–π—Ç–∞—Ç—ã–Ω –¥–µ–∫–æ–¥—Ç–∞—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–ª–∞—Ä—ã–Ω “õ–∞—Ä–∞—Å—Ç—ã—Ä–∞–º—ã–∑.\n",
    "* –ú“±–Ω–¥–∞“ì—ã –∞—Ä—Ç—ã“õ “Ø–π—Ä–µ–Ω—É —Å–µ–±–µ–±—ñ ‚Äî —Ç—Ä–µ–Ω–∏–Ω–≥ –∂–∏—ã–Ω—Ç—ã“ì—ã–Ω—ã“£ ”©—Ç–µ –∫—ñ—à–∫–µ–Ω—Ç–∞–π –±–æ–ª—É—ã –∂”ô–Ω–µ –º–æ–¥–µ–ª—å–¥—ñ“£ –æ–Ω—ã —Ç—ã–º –∫”©–ø —Ä–µ—Ç “õ–∞–π—Ç–∞–ª–∞–ø –æ“õ—É—ã.\n",
    "  * –ú“±–Ω–¥–∞“ì—ã LLM —Ç—Ä–µ–Ω–∏–Ω–≥—ñ –Ω–µ–≥—ñ–∑—ñ–Ω–µ–Ω –æ“õ—É –º–∞“õ—Å–∞—Ç—ã–Ω–∞ –∞—Ä–Ω–∞–ª“ì–∞–Ω; –±–∞—Å—Ç—ã—Å—ã ‚Äî –º–æ–¥–µ–ª—å–¥—ñ“£ –±–∞–π–ª–∞–Ω—ã—Å—Ç—ã –º”ô—Ç—ñ–Ω —Ç—É–¥—ã—Ä–∞ –∞–ª–∞—Ç—ã–Ω—ã–Ω –∫”©—Ä—É.\n",
    "  * –ë“±–ª –º–æ–¥–µ–ª—å–¥—ñ “õ—ã–º–±–∞—Ç –∂–∞–±–¥—ã“õ—Ç–∞—Ä–¥–∞ –∞–ø—Ç–∞–ª–∞–ø –Ω–µ–º–µ—Å–µ –∞–π–ª–∞–ø –∂–∞—Ç—Ç—ã“õ—Ç—ã—Ä—É–¥—ã“£ –æ—Ä–Ω—ã–Ω–∞, –±—ñ–∑ –∫–µ–π—ñ–Ω—ñ—Ä–µ–∫ –∞–ª–¥—ã–Ω –∞–ª–∞ –∂–∞—Ç—Ç—ã“õ—Ç—ã—Ä—ã–ª“ì–∞–Ω —Å–∞–ª–º–∞“õ—Ç–∞—Ä–¥—ã –∂“Ø–∫—Ç–µ–π–º—ñ–∑.\n",
    "---\n",
    "* –ì–ª—è–¥—è –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã—à–µ, –º—ã –≤–∏–¥–∏–º, —á—Ç–æ –º–æ–¥–µ–ª—å –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–ª–æ–≤, —Ç–æ–≥–¥–∞ –∫–∞–∫ –±–ª–∏–∂–µ –∫ –∫–æ–Ω—Ü—É –æ–Ω–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏ –±–æ–ª–µ–µ –∏–ª–∏ –º–µ–Ω–µ–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.\n",
    "* –û–¥–Ω–∞–∫–æ, –ø–æ –∑–Ω–∞—á–µ–Ω–∏—è–º –ø–æ—Ç–µ—Ä—å –Ω–∞ –æ–±—É—á–∞—é—â–µ–º –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–∞—Ö –≤–∏–¥–Ω–æ, —á—Ç–æ –º–æ–¥–µ–ª—å –Ω–∞—á–∏–Ω–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–∞—Ç—å—Å—è.\n",
    "* –ï—Å–ª–∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ—Ç—Ä—ã–≤–∫–æ–≤, –Ω–∞–ø–∏—Å–∞–Ω–Ω—ã—Ö –µ—é –∫ –∫–æ–Ω—Ü—É –æ–±—É—á–µ–Ω–∏—è, –º–æ–∂–Ω–æ –∑–∞–º–µ—Ç–∏—Ç—å, —á—Ç–æ –æ–Ω–∏ –±—É–∫–≤–∞–ª—å–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—Å—è –≤ –æ–±—É—á–∞—é—â–µ–º –Ω–∞–±–æ—Ä–µ ‚Äî –º–æ–¥–µ–ª—å –ø—Ä–æ—Å—Ç–æ –∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ.\n",
    "* –ü–æ–∑–∂–µ –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –≤ –Ω–µ–∫–æ—Ç–æ—Ä–æ–π —Å—Ç–µ–ø–µ–Ω–∏ —É–º–µ–Ω—å—à–∏—Ç—å —ç—Ç–æ –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ.\n",
    "* –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –∑–¥–µ—Å—å –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –∏–∑-–∑–∞ –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–æ–≥–æ –æ–±—É—á–∞—é—â–µ–≥–æ –Ω–∞–±–æ—Ä–∞ –∏ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏—Ç–µ—Ä–∞—Ü–∏–π.\n",
    "  * –û–±—É—á–µ–Ω–∏–µ LLM –∑–¥–µ—Å—å —Å–ª—É–∂–∏—Ç –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º —Ü–µ–ª—è–º; –Ω–∞–º –≤–∞–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ –º–æ–¥–µ–ª—å —Å–ø–æ—Å–æ–±–Ω–∞ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–≤—è–∑–Ω—ã–π —Ç–µ–∫—Å—Ç.\n",
    "  * –í–º–µ—Å—Ç–æ —Ç–æ–≥–æ —á—Ç–æ–±—ã —Ç—Ä–∞—Ç–∏—Ç—å –Ω–µ–¥–µ–ª–∏ –∏–ª–∏ –º–µ—Å—è—Ü—ã –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ —ç—Ç–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –æ–≥—Ä–æ–º–Ω—ã—Ö –æ–±—ä–µ–º–∞—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –¥–æ—Ä–æ–≥–æ–º –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–∏, –º—ã –ø–æ–∑–∂–µ –∑–∞–≥—Ä—É–∑–∏–º –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dff7960",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-2.webp\" width=1000px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fe5389",
   "metadata": {},
   "source": [
    "## 4.3 –ö–µ–∑–¥–µ–π—Å–æ“õ—Ç—ã“õ—Ç—ã –±–∞—Å“õ–∞—Ä—É“ì–∞ –∞—Ä–Ω–∞–ª“ì–∞–Ω –¥–µ–∫–æ–¥—Ç–∞—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–ª–∞—Ä—ã\n",
    "## 4.3 –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å—é\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0a0ee2",
   "metadata": {},
   "source": [
    "* –ì–µ–Ω–µ—Ä–∞—Ü–∏—è (inference) –ø—Ä–æ—Ü–µ—Å—ñ –∂–æ“ì–∞—Ä—ã–¥–∞ “Ø–π—Ä–µ—Ç—ñ–ª–≥–µ–Ω GPT —Å–∏—è“õ—Ç—ã —à–∞“ì—ã–Ω LLM “Ø—à—ñ–Ω –∞—Ä–∑–∞–Ω, —Å–æ–Ω–¥—ã“õ—Ç–∞–Ω –æ–Ω—ã –æ—Ä—ã–Ω–¥–∞—É “Ø—à—ñ–Ω GPU “õ–æ–ª–¥–∞–Ω—É–¥—ã“£ “õ–∞–∂–µ—Ç—ñ –∂–æ“õ.\n",
    "* –ë“±—Ä—ã–Ω“ì—ã –±”©–ª—ñ–º–¥–µ –ø–∞–π–¥–∞–ª–∞–Ω“ì–∞–Ω “õ–∞—Ä–∞–ø–∞–π—ã–º –æ“õ—É —Ñ—É–Ω–∫—Ü–∏—è—Å—ã–Ω—ã“£ —ñ—à—ñ–Ω–¥–µ “õ–æ–ª–¥–∞–Ω—ã–ª“ì–∞–Ω `generate_text_simple` —Ñ—É–Ω–∫—Ü–∏—è—Å—ã–Ω –ø–∞–π–¥–∞–ª–∞–Ω–∞ –æ—Ç—ã—Ä—ã–ø, –±—ñ–∑ –∂–∞“£–∞ –º”ô—Ç—ñ–Ω–¥—ñ –±—ñ—Ä —Å”©–∑–¥–µ–Ω (–Ω–µ–º–µ—Å–µ —Ç–æ–∫–µ–Ω–Ω–µ–Ω) –±—ñ—Ä—Ç—ñ–Ω–¥–µ–ø —Ç—É–¥—ã—Ä—É—ã–º—ã–∑“ì–∞ –±–æ–ª–∞–¥—ã.\n",
    "* –ì–µ–Ω–µ—Ä–∞—Ü–∏—è–ª–∞–Ω“ì–∞–Ω —Ç–æ–∫–µ–Ω ‚Äî –±“±–ª —Å”©–∑–¥—ñ–∫ “õ–æ—Ä—ã–Ω–¥–∞“ì—ã –±–∞—Ä–ª—ã“õ —Ç–æ–∫–µ–Ω–¥–µ—Ä–¥—ñ“£ —ñ—à—ñ–Ω–¥–µ –µ“£ –∂–æ“ì–∞—Ä—ã —ã“õ—Ç–∏–º–∞–ª–¥—ã“õ –º”ô–Ω—ñ–Ω–µ —Å”ô–π–∫–µ—Å –∫–µ–ª–µ—Ç—ñ–Ω —Ç–æ–∫–µ–Ω.\n",
    "***\n",
    "* –ì–µ–Ω–µ—Ä–∞—Ü–∏—è (inference) –Ω–µ–¥–æ—Ä–æ–≥ –¥–ª—è –Ω–µ–±–æ–ª—å—à–æ–π LLM, –∫–∞–∫ –æ–±—É—á–µ–Ω–Ω–∞—è –≤—ã—à–µ –º–æ–¥–µ–ª—å GPT, –ø–æ—ç—Ç–æ–º—É –Ω–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU –¥–ª—è –≤—ã–≤–æ–¥–∞, –¥–∞–∂–µ –µ—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ –µ–≥–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.\n",
    "* –° –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–∏ `generate_text_simple`  –º–æ–∂–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç –ø–æ –æ–¥–Ω–æ–º—É —Å–ª–æ–≤—É (–∏–ª–∏ —Ç–æ–∫–µ–Ω—É) –∑–∞ —Ä–∞–∑.\n",
    "* –°–ª–µ–¥—É—é—â–∏–π —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω ‚Äî —ç—Ç–æ —Ç–æ–∫–µ–Ω, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –Ω–∞–∏–±–æ–ª—å—à–µ–º—É –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Å–ª–æ–≤–∞—Ä–µ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de30023",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c360a2e",
   "metadata": {},
   "source": [
    "* –ñ–æ“ì–∞—Ä—ã–¥–∞“ì—ã `generate_text_simple` —Ñ—É–Ω–∫—Ü–∏—è—Å—ã–Ω –±—ñ—Ä–Ω–µ—à–µ —Ä–µ—Ç –æ—Ä—ã–Ω–¥–∞—Å–∞“õ —Ç–∞, LLM ”ô—Ä–¥–∞–π—ã–º –±—ñ—Ä–¥–µ–π –Ω”ô—Ç–∏–∂–µ —à—ã“ì–∞—Ä–∞–¥—ã.\n",
    "* –ï–Ω–¥—ñ –±—ñ–∑ –µ–∫—ñ *–¥–µ–∫–æ–¥—Ç–∞—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–ª–∞—Ä—ã–Ω* ‚Äî –µ–Ω–≥—ñ–∑–µ–º—ñ–∑: *—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞–ª—ã“õ –º–∞—Å—à—Ç–∞–±—Ç–∞—É (temperature scaling)* –∂”ô–Ω–µ *top-k* “Ø–ª–≥—ñ–ª–µ—É (sampling).\n",
    "* –ë“±–ª —Ç”ô—Å—ñ–ª–¥–µ—Ä –º–æ–¥–µ–ª—å–≥–µ –∂–∞—Å–∞–ª“ì–∞–Ω –º”ô—Ç—ñ–Ω–Ω—ñ“£ –∫–µ–∑–¥–µ–π—Å–æ“õ—Ç—ã“ì—ã –º–µ–Ω ”ô—Ä—Ç“Ø—Ä–ª—ñ–ª—ñ–≥—ñ–Ω –±–∞—Å“õ–∞—Ä—É“ì–∞ –º“Ø–º–∫—ñ–Ω–¥—ñ–∫ –±–µ—Ä–µ–¥—ñ.\n",
    "***\n",
    "* –î–∞–∂–µ –µ—Å–ª–∏ –º—ã –≤—ã–ø–æ–ª–Ω–∏–º —Ñ—É–Ω–∫—Ü–∏—é `generate_text_simple` –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑, LLM –≤—Å–µ–≥–¥–∞ –±—É–¥–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.\n",
    "* –¢–µ–ø–µ—Ä—å –º—ã –≤–≤–µ–¥—ë–º –¥–≤–µ *—Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è*: *–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã (temperature scaling)* –∏ *top-k* –≤—ã–±–æ—Ä–∫—É (sampling).\n",
    "* –≠—Ç–∏ –º–µ—Ç–æ–¥—ã –ø–æ–∑–≤–æ–ª—è—Ç –º–æ–¥–µ–ª–∏ —É–ø—Ä–∞–≤–ª—è—Ç—å —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å—é –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ–º —Å–æ–∑–¥–∞–≤–∞–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c99e503",
   "metadata": {},
   "source": [
    "### 4.3.1 –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞–ª—ã“õ –º–∞—Å—à—Ç–∞–±—Ç–∞—É\n",
    "### 4.3.1 –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d244b68d",
   "metadata": {},
   "source": [
    "* –ë“±“ì–∞–Ω –¥–µ–π—ñ–Ω –±—ñ–∑ –∫–µ–ª–µ—Å—ñ —Ç–æ–∫–µ–Ω —Ä–µ—Ç—ñ–Ω–¥–µ –µ“£ –∂–æ“ì–∞—Ä—ã —ã“õ—Ç–∏–º–∞–ª–¥—ã“ì—ã –±–∞—Ä —Ç–æ–∫–µ–Ω–¥—ñ —Ç–∞“£–¥–∞–ø –∞–ª–∞—Ç—ã–Ω–±—ã–∑ (`torch.argmax` –ø–∞–π–¥–∞–ª–∞–Ω—ã–ø).\n",
    "* ”®–∑–≥–µ—à–µ  —Ç–æ–∫–µ–Ω —Ç–∞“£–¥–∞–ø –∞–ª—É “Ø—à—ñ–Ω, –∫–µ–ª–µ—Å—ñ —Ç–æ–∫–µ–Ω–¥—ñ —ã“õ—Ç–∏–º–∞–ª–¥—ã“õ—Ç–∞—Ä —Ç–∞—Ä–∞–ª—É—ã–Ω–∞–Ω –∫–µ–∑–¥–µ–π—Å–æ“õ —Ç–∞“£–¥–∞—É –∞—Ä“õ—ã–ª—ã –∞–ª—É“ì–∞ –±–æ–ª–∞–¥—ã ‚Äî —è“ì–Ω–∏ `torch.multinomial(probs, num_samples=1)` —Ñ—É–Ω–∫—Ü–∏—è—Å—ã–Ω “õ–æ–ª–¥–∞–Ω–∞–º—ã–∑.\n",
    "* –ú“±–Ω–¥–∞ ”ô—Ä–±—ñ—Ä –∏–Ω–¥–µ–∫—Å—Ç—ñ“£ —Ç–∞“£–¥–∞–ª—É –º“Ø–º–∫—ñ–Ω–¥—ñ–≥—ñ –æ–Ω—ã“£ –µ–Ω–≥—ñ–∑—É —Ç–µ–Ω–∑–æ—Ä—ã–Ω–¥–∞“ì—ã —ã“õ—Ç–∏–º–∞–ª–¥—ã“ì—ã–Ω–∞ —Å”ô–π–∫–µ—Å –∫–µ–ª–µ–¥—ñ.\n",
    "***\n",
    "* –†–∞–Ω–µ–µ –º—ã –≤—Å–µ–≥–¥–∞ –≤—ã–±–∏—Ä–∞–ª–∏ —Ç–æ–∫–µ–Ω —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –∫–∞–∫ —Å–ª–µ–¥—É—é—â–∏–π, –∏—Å–ø–æ–ª—å–∑—É—è `torch.argmax`.\n",
    "* –ß—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ, –º–æ–∂–Ω–æ –≤—ã–±–∏—Ä–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω –∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Å –ø–æ–º–æ—â—å—é `torch.multinomial(probs, num_samples=1)`.\n",
    "* –ó–¥–µ—Å—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—ã–±–æ—Ä–∞ –∫–∞–∂–¥–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –µ–≥–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤–æ –≤—Ö–æ–¥–Ω–æ–º —Ç–µ–Ω–∑–æ—Ä–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a485c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# Suppose input is \"every effort moves you\", and the LLM\n",
    "# returns the following logits for the next token:\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# The next generated token is then as follows:\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4623096",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243cc2c9",
   "metadata": {},
   "source": [
    "* `torch.argmax` –∞—Ä“õ—ã–ª—ã –∞–Ω—ã“õ—Ç–∞—É–¥—ã“£ –æ—Ä–Ω—ã–Ω–∞, –±—ñ–∑ `torch.multinomial(probas, num_samples=1)` —Ñ—É–Ω–∫—Ü–∏—è—Å—ã–Ω “õ–æ–ª–¥–∞–Ω—ã–ø, softmax —Ç–∞—Ä–∞–ª—É—ã–Ω–∞–Ω –∫–µ–∑–¥–µ–π—Å–æ“õ —Ç–∞“£–¥–∞—É –∞—Ä“õ—ã–ª—ã  –µ“£ —ã“õ—Ç–∏–º–∞–ª —Ç–æ–∫–µ–Ω–¥—ñ –∞–Ω—ã“õ—Ç–∞–π–º—ã–∑.\n",
    "* –ú—ã—Å–∞–ª —Ä–µ—Ç—ñ–Ω–¥–µ, –±–∞—Å—Ç–∞–ø“õ—ã softmax —ã“õ—Ç–∏–º–∞–ª–¥—ã“õ—Ç–∞—Ä—ã–Ω –ø–∞–π–¥–∞–ª–∞–Ω—ã–ø –∫–µ–ª–µ—Å—ñ —Ç–æ–∫–µ–Ω–¥—ñ 1 000 —Ä–µ—Ç —Ç–∞“£–¥–∞“ì–∞–Ω–¥–∞ –Ω–µ –±–æ–ª–∞—Ç—ã–Ω—ã–Ω –∫”©—Ä–µ–π—ñ–∫:\n",
    "***\n",
    "* –í–º–µ—Å—Ç–æ —Ç–æ–≥–æ —á—Ç–æ–±—ã –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã–π —Ç–æ–∫–µ–Ω —Å –ø–æ–º–æ—â—å—é `torch.argmax`, –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º `torch.multinomial(probas, num_samples=1)`, —á—Ç–æ–±—ã –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –µ–≥–æ, –≤—ã–±–∏—Ä–∞—è —Å–ª—É—á–∞–π–Ω–æ –∏–∑ softmax-—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è.\n",
    "* –î–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏ –ø–æ—Å–º–æ—Ç—Ä–∏–º, —á—Ç–æ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç, –µ—Å–ª–∏ –≤—ã–±—Ä–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω 1 000 —Ä–∞–∑, –∏—Å–ø–æ–ª—å–∑—É—è –∏—Å—Ö–æ–¥–Ω—ã–µ softmax-–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387297d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9c9975",
   "metadata": {},
   "source": [
    "* –ë—ñ–∑ —Ç–∞“£–¥–∞—É –ø—Ä–æ—Ü–µ—Å—ñ–Ω *temperature scaling* –¥–µ–ø –∞—Ç–∞–ª–∞—Ç—ã–Ω “±“ì—ã–º –∞—Ä“õ—ã–ª—ã –±–∞—Å“õ–∞—Ä–∞ –∞–ª–∞–º—ã–∑.\n",
    "* \"Temperature scaling\" ‚Äî –±“±–ª –∂–∞–π “ì–∞–Ω–∞ –ª–æ–≥–∏—Ç—Ç–µ—Ä–¥—ñ 0-–¥–µ–Ω “Ø–ª–∫–µ–Ω —Å–∞–Ω“ì–∞ –±”©–ª—É –¥–µ–≥–µ–Ω —Å”©–∑.\n",
    "* –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –º”ô–Ω—ñ 1-–¥–µ–Ω “Ø–ª–∫–µ–Ω –±–æ–ª“ì–∞–Ω–¥–∞, softmax “õ–æ–ª–¥–∞–Ω“ì–∞–Ω–Ω–∞–Ω –∫–µ–π—ñ–Ω —Ç–æ–∫–µ–Ω —ã“õ—Ç–∏–º–∞–ª–¥—ã“õ—Ç–∞—Ä—ã –±—ñ—Ä–∫–µ–ª–∫—ñ–ª–µ—É “Ø–ª–µ—Å—Ç—ñ—Ä—ñ–ª–µ–¥—ñ.\n",
    "* –ê–ª —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ 1-–¥–µ–Ω –∫—ñ—à—ñ –±–æ–ª—Å–∞, softmax “õ–æ–ª–¥–∞–Ω“ì–∞–Ω–Ω–∞–Ω –∫–µ–π—ñ–Ω “Ø–ª–µ—Å—Ç—ñ—Ä—É —Å–µ–Ω—ñ–º–¥—ñ—Ä–µ–∫ (”©—Ç–∫—ñ—Ä –Ω–µ–º–µ—Å–µ —à–æ“ì—ã—Ä–ª–∞–Ω“ì–∞–Ω) –±–æ–ª–∞–¥—ã.\n",
    "***\n",
    "* –ú—ã –º–æ–∂–µ–º —É–ø—Ä–∞–≤–ª—è—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ–º –≤—ã–±–æ—Ä–∞ —Å –ø–æ–º–æ—â—å—é –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º *temperature scaling* (–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã).\n",
    "* \"Temperature scaling\" ‚Äî —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ –¥–µ–ª–µ–Ω–∏–µ –ª–æ–≥–∏—Ç–æ–≤ –Ω–∞ —á–∏—Å–ª–æ –±–æ–ª—å—à–µ –Ω—É–ª—è.\n",
    "* –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –±–æ–ª—å—à–µ 1 –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –±–æ–ª–µ–µ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è softmax.\n",
    "* –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –º–µ–Ω—å—à–µ 1 –¥–µ–ª–∞–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –±–æ–ª–µ–µ —É–≤–µ—Ä–µ–Ω–Ω—ã–º (—Ä–µ–∑–∫–∏–º –∏–ª–∏ –ø–∏–∫–æ–≤—ã–º) –ø–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57394c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce81effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aca7a75",
   "metadata": {},
   "source": [
    "* Temperature –º”ô–Ω—ñ 0.1 –±–æ–ª“ì–∞–Ω–¥–∞ “õ–∞–π—Ç–∞ –º–∞—Å—à—Ç–∞–±—Ç–∞—É –Ω”ô—Ç–∏–∂–µ—Å—ñ–Ω–¥–µ “Ø–ª–µ—Å—Ç—ñ—Ä—É –∞–Ω–∞“ì“±—Ä–ª—ã–º ”©—Ç–∫—ñ—Ä –±–æ–ª—ã–ø, `torch.argmax` —Ç”ô—Å—ñ–ª—ñ–Ω–µ “±“õ—Å–∞–π –±–∞—Å—Ç–∞–π–¥—ã ‚Äî —è“ì–Ω–∏ –µ“£ —ã“õ—Ç–∏–º–∞–ª —Å”©–∑ –¥–µ—Ä–ª—ñ–∫ ”ô—Ä“õ–∞—à–∞–Ω —Ç–∞“£–¥–∞–ª–∞–¥—ã:\n",
    "***\n",
    "* –ú—ã –º–æ–∂–µ–º –∑–∞–º–µ—Ç–∏—Ç—å, —á—Ç–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–æ–π 0.1 –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –±–æ–ª–µ–µ —Ä–µ–∑–∫–æ–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é, –ø—Ä–∏–±–ª–∏–∂–∞—é—â–µ–º—É—Å—è –∫ `torch.argmax`, —Ç–∞–∫ —á—Ç–æ –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ–µ —Å–ª–æ–≤–æ –ø–æ—á—Ç–∏ –≤—Å–µ–≥–¥–∞ –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1177bb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sampled_tokens(scaled_probas[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ff4d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sampled_tokens(scaled_probas[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35931d5b",
   "metadata": {},
   "source": [
    "### 4.3.2 Top-k —ñ—Ä—ñ–∫—Ç–µ—É\n",
    "### 4.3.2 Top-k –≤—ã–±–æ—Ä–∫–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242f167d",
   "metadata": {},
   "source": [
    "* –®—ã“ì—ã—Å “õ“±–±—ã–ª–º–∞–ª—ã“ì—ã–Ω –∞—Ä—Ç—Ç—ã—Ä—É –∂”ô–Ω–µ –º–∞“ì—ã–Ω–∞—Å—ã–∑ —Å”©–π–ª–µ–º–¥–µ—Ä–¥—ñ“£ —ã“õ—Ç–∏–º–∞–ª–¥—ã“ì—ã–Ω –∞–∑–∞–π—Ç—É “Ø—à—ñ–Ω, –±—ñ–∑ —Ç–∞“£–¥–∞—É–¥—ã –µ“£ —ã“õ—Ç–∏–º–∞–ª —Ç–æ–ø-k —Ç–æ–∫–µ–Ω–¥–µ—Ä–º–µ–Ω —à–µ–∫—Ç–µ—É–≥–µ –±–æ–ª–∞–¥—ã:\n",
    "***\n",
    "* –ß—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –≤—ã–≤–æ–¥–∞ –∏ —É–º–µ–Ω—å—à–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –º–æ–∂–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –≤—ã–±–æ—Ä–∫—É —Ç–æ–ø-k –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã–º–∏ —Ç–æ–∫–µ–Ω–∞–º–∏:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b87161e",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/topk.webp\" width=1000px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2970dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa36dd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float(\"-inf\")), \n",
    "    other=next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5c52a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4c963e",
   "metadata": {},
   "source": [
    "### 4.3.3 –ú”ô—Ç—ñ–Ω –≥–µ–Ω–µ—Ä–∞—Ü–∏—è–ª–∞—É —Ñ—É–Ω–∫—Ü–∏—è—Å—ã–Ω ”©–∑–≥–µ—Ä—Ç—É\n",
    "### 4.3.3 –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1874b2c7",
   "metadata": {},
   "source": [
    "* –ê–ª–¥—ã“£“ì—ã –µ–∫—ñ –±”©–ª—ñ–º–¥–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –±–æ–π—ã–Ω—à–∞ —ñ—Ä—ñ–∫—Ç–µ—É –∂”ô–Ω–µ top-k —ñ—Ä—ñ–∫—Ç–µ—É —Ç”ô—Å—ñ–ª–¥–µ—Ä—ñ —Ç–∞–Ω—ã—Å—Ç—ã—Ä—ã–ª–¥—ã\n",
    "* –ï–Ω–¥—ñ –æ—Å—ã –µ–∫—ñ “±“ì—ã–º–¥—ã “õ–æ–ª–¥–∞–Ω—ã–ø,  `generate_text_simple` —Ñ—É–Ω–∫—Ü–∏—è—Å—ã–Ω ”©–∑–≥–µ—Ä—Ç—ñ–ø, –∂–∞“£–∞ `generate` —Ñ—É–Ω–∫—Ü–∏—è—Å—ã–Ω “õ“±—Ä–∞–º—ã–∑:\n",
    "***\n",
    "* –í –¥–≤—É—Ö –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –ø–æ–¥—Ä–∞–∑–¥–µ–ª–∞—Ö –±—ã–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –≤—ã–±–æ—Ä–∫–∞ –ø–æ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–µ –∏ –≤—ã–±–æ—Ä–∫–∞ top-k\n",
    "* –¢–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç—Ç–∏ –¥–≤–∞ –ø–æ–Ω—è—Ç–∏—è, —á—Ç–æ–±—ã –∏–∑–º–µ–Ω–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é `generate_text_simple`–∏  —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é `generate`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1e425f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # New (not in book): numerical stability tip to get equivalent results on mps device\n",
    "            # subtract rowwise max before softmax\n",
    "            logits = logits - logits.max(dim=-1, keepdim=True).values\n",
    "            \n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be29e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd58cb06",
   "metadata": {},
   "source": [
    "## 4.4 PyTorch-—Ç–∞ –º–æ–¥–µ–ª—å —Å–∞–ª–º–∞“õ—Ç–∞—Ä—ã–Ω –∂“Ø–∫—Ç–µ—É –∂”ô–Ω–µ —Å–∞“õ—Ç–∞—É\n",
    "## 4.4 –ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏ –≤ PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098728e8",
   "metadata": {},
   "source": [
    "- Training LLMs is computationally expensive, so it's crucial to be able to save and load LLM weights\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-3.webp\" width=1000px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58501951",
   "metadata": {},
   "source": [
    "* PyTorch-—Ç–∞  –º–æ–¥–µ–ª—å —Å–∞–ª–º–∞“õ—Ç–∞—Ä—ã–Ω (`state_dict`) –¥–µ–ø –∞—Ç–∞–ª–∞—Ç—ã–Ω “õ“±—Ä—ã–ª—ã–º–¥—ã `torch.save` —Ñ—É–Ω–∫—Ü–∏—è—Å—ã –∞—Ä“õ—ã–ª—ã —Å–∞“õ—Ç–∞—É“ì–∞ –±–æ–ª–∞–¥—ã:\n",
    "* –í PyTorch —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏, —Ç–∞–∫ –Ω–∞–∑—ã–≤–∞–µ–º—ã–π `state_dict`, –ø—Ä–∏–º–µ–Ω—è—è —Ñ—É–Ω–∫—Ü–∏—é `torch.save` –∫ –º–µ—Ç–æ–¥—É `.state_dict()`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734d118",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ddfcc",
   "metadata": {},
   "source": [
    "* –°–æ–¥–∞–Ω –∫–µ–π—ñ–Ω –º–æ–¥–µ–ª—å–¥—ñ“£ —Å–∞–ª–º–∞“õ—Ç–∞—Ä—ã–Ω –∂–∞“£–∞ `GPTModel` –¥–∞–Ω–∞—Å—ã–Ω–∞ –∫–µ–ª–µ—Å—ñ–¥–µ–π —Ç“Ø—Ä–¥–µ –∂“Ø–∫—Ç–µ—É–≥–µ –±–æ–ª–∞–¥—ã:\n",
    "* –ó–∞—Ç–µ–º –º—ã –º–æ–∂–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ –≤ –Ω–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏ `GPTModel` —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f1f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4d5f4a",
   "metadata": {},
   "source": [
    "* LLM –º–æ–¥–µ–ª—å–¥–µ—Ä—ñ–Ω –∫”ô–¥—ñ–º–≥—ñ `SGD` –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã –æ—Ä–Ω—ã–Ω–∞ `Adam` –Ω–µ–º–µ—Å–µ `AdamW` —Å–∏—è“õ—Ç—ã  –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–ª–∞—Ä–º–µ–Ω –∂–∞—Ç—Ç—ã“õ—Ç—ã—Ä—É –∂–∏—ñ “õ–æ–ª–¥–∞–Ω—ã–ª–∞–¥—ã.\n",
    "* –ë“±–ª –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–ª–∞—Ä ”ô—Ä–±—ñ—Ä –º–æ–¥–µ–ª—å —Å–∞–ª–º–∞“ì—ã “Ø—à—ñ–Ω “õ–æ—Å—ã–º—à–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–ª–µ—Ä–¥—ñ —Å–∞“õ—Ç–∞–π–¥—ã, —Å–æ–Ω–¥—ã“õ—Ç–∞–Ω –µ–≥–µ—Ä –±–æ–ª–∞—à–∞“õ—Ç–∞ –∞–ª–¥—ã–Ω –∞–ª–∞ –æ“õ—ã—Ç—É–¥—ã –∂–∞–ª“ì–∞—Å—Ç—ã—Ä—É–¥—ã –∂–æ—Å–ø–∞—Ä–ª–∞—Å–∞“õ, –æ–ª–∞—Ä–¥—ã –¥–∞ —Å–∞“õ—Ç–∞—É –æ—Ä—ã–Ω–¥—ã:\n",
    "***\n",
    "* –ß–∞—Å—Ç–æ LLM –æ–±—É—á–∞—é—Ç —Å –ø–æ–º–æ—â—å—é –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤, —Ç–∞–∫–∏—Ö –∫–∞–∫ `Adam` –∏–ª–∏ `AdamW`, –≤–º–µ—Å—Ç–æ –æ–±—ã—á–Ω–æ–≥–æ `SGD`.\n",
    "* –≠—Ç–∏  –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã —Ö—Ä–∞–Ω—è—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏, –ø–æ—ç—Ç–æ–º—É –∏–º–µ–µ—Ç —Å–º—ã—Å–ª —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Ö, –µ—Å–ª–∏ –º—ã –ø–ª–∞–Ω–∏—Ä—É–µ–º –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –ø–æ–∑–∂–µ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90446ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c692ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e22b64a",
   "metadata": {},
   "source": [
    "## 4.5 OpenAI-–¥–µ–Ω –∞–ª–¥—ã–Ω –∞–ª–∞ “Ø–π—Ä–µ—Ç—ñ–ª–≥–µ–Ω —Å–∞–ª–º–∞“õ—Ç–∞—Ä–¥—ã –∂“Ø–∫—Ç–µ—É\n",
    "## 4.5 –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –≤–µ—Å–æ–≤ –∏–∑ OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59038d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "tqdm version: 4.67.1\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
    "print(\"tqdm version:\", version(\"tqdm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183f251b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded to gpt2-small-124M.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"drop_rate\": 0.0,       # Dropout rate\n",
    "    \"qkv_bias\": True        # Query-key-value bias\n",
    "}\n",
    "\n",
    "file_name = \"gpt2-small-124M.pth\"\n",
    "# file_name = \"gpt2-medium-355M.pth\"\n",
    "# file_name = \"gpt2-large-774M.pth\"\n",
    "# file_name = \"gpt2-xl-1558M.pth\"\n",
    "\n",
    "url = f\"https://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/{file_name}\"\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    print(f\"Downloaded to {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089b37f7",
   "metadata": {},
   "source": [
    "* “ö–æ—Å—ã–º—à–∞ `\"355M\"`, `\"774M\"` –∂”ô–Ω–µ `\"1558M\"` –º”ô–Ω–¥–µ—Ä—ñ –¥–µ `model_size` –∞—Ä–≥—É–º–µ–Ω—Ç—ñ —Ä–µ—Ç—ñ–Ω–¥–µ “õ–æ–ª–¥–∞—É“ì–∞ –±–æ–ª–∞–¥—ã.\n",
    "* ”ò—Ä —Ç“Ø—Ä–ª—ñ ”©–ª—à–µ–º–¥–µ–≥—ñ –±“±–ª –º–æ–¥–µ–ª—å–¥–µ—Ä–¥—ñ“£ –∞–π—ã—Ä–º–∞—à—ã–ª—ã“ì—ã —Ç”©–º–µ–Ω–¥–µ–≥—ñ —Å—É—Ä–µ—Ç—Ç–µ –∫”©—Ä—Å–µ—Ç—ñ–ª–≥–µ–Ω:\n",
    "***\n",
    "* –í –∫–∞—á–µ—Å—Ç–≤–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –∞—Ä–≥—É–º–µ–Ω—Ç—ã `model_size` —Ç–∞–∫–∂–µ –º–æ–≥—É—Ç –ø—Ä–∏–Ω–∏–º–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è `\"355M\"`, `\"774M\"` –∏ `\"1558M\"`.\n",
    "* –†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏ —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –ø–æ–∫–∞–∑–∞–Ω–∞ –Ω–∞ —Ä–∏—Å—É–Ω–∫–µ –Ω–∏–∂–µ:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f61fe3",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/gpt-sizes.webp?timestamp=123\" width=1000px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bce30a",
   "metadata": {},
   "source": [
    "* –ñ–æ“ì–∞—Ä—ã–¥–∞ –±—ñ–∑ 124M GPT-2 –º–æ–¥–µ–ª—ñ–Ω—ñ“£ —Å–∞–ª–º–∞“õ—Ç–∞—Ä—ã–Ω Python-“ì–∞ –∂“Ø–∫—Ç–µ–¥—ñ–∫, –±—ñ—Ä–∞“õ –æ–ª–∞—Ä–¥—ã ”©–∑—ñ–º—ñ–∑–¥—ñ“£ `GPTModel` “Ø–ª–≥—ñ—Å—ñ–Ω–µ ”ô–ª—ñ –¥–µ –æ—Ä–Ω–∞—Ç—É—ã–º—ã–∑ –∫–µ—Ä–µ–∫.\n",
    "* –ê–ª–¥—ã–º–µ–Ω –∂–∞“£–∞ `GPTModel` –¥–∞–Ω–∞—Å—ã–Ω –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è–ª–∞–π–º—ã–∑.\n",
    "* –ù–µ–≥—ñ–∑–≥—ñ GPT –º–æ–¥–µ–ª—ñ–Ω–¥–µ –∫”©–ø–±–∞—Å—Ç—ã –∑–µ–π—ñ–Ω (multi-head attention) –º–æ–¥—É–ª—ñ–Ω–¥–µ–≥—ñ —Å“±—Ä–∞—É (query), –∫—ñ–ª—Ç (key) –∂”ô–Ω–µ –º”ô–Ω (value) –º–∞—Ç—Ä–∏—Ü–∞–ª–∞—Ä—ã “Ø—à—ñ–Ω —Å—ã–∑—ã“õ—Ç—ã“õ “õ–∞–±–∞—Ç—Ç–∞—Ä (linear layers) —ã“ì—ã—Å—É –≤–µ–∫—Ç–æ—Ä–ª–∞—Ä—ã–º–µ–Ω (bias vectors) –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è–ª–∞–Ω“ì–∞–Ω, –±“±–ª –º—ñ–Ω–¥–µ—Ç—Ç—ñ –µ–º–µ—Å; –∞–ª–∞–π–¥–∞ —Å–∞–ª–º–∞“õ—Ç–∞—Ä–¥—ã –¥“±—Ä—ã—Å –∂“Ø–∫—Ç–µ—É “Ø—à—ñ–Ω –±—ñ–∑ –¥–µ ”©–∑—ñ–º—ñ–∑–¥—ñ“£ –∂“Ø–∑–µ–≥–µ –∞—Å—ã—Ä—É—ã–º—ã–∑–¥–∞ `qkv_bias` –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–Ω `True` –µ—Ç—ñ–ø –æ—Ä–Ω–∞—Ç—É—ã–º—ã–∑ –∫–µ—Ä–µ–∫.\n",
    "* –°–æ–Ω–¥–∞–π-–∞“õ, –±—ñ–∑ –±–∞—Å—Ç–∞–ø“õ—ã GPT-2 –º–æ–¥–µ–ª—å–¥–µ—Ä—ñ–Ω–¥–µ “õ–æ–ª–¥–∞–Ω—ã–ª“ì–∞–Ω `1024` —Ç–æ–∫–µ–Ω–¥—ñ–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç “±–∑—ã–Ω–¥—ã“ì—ã–Ω –ø–∞–π–¥–∞–ª–∞–Ω–∞–º—ã–∑.\n",
    "***\n",
    "* –í—ã—à–µ –º—ã –∑–∞–≥—Ä—É–∑–∏–ª–∏ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ GPT-2 —Å 124 –º–∏–ª–ª–∏–æ–Ω–∞–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ Python, –æ–¥–Ω–∞–∫–æ –Ω–∞–º –≤—Å—ë –µ—â—ë –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –∏—Ö –≤ –Ω–∞—à —ç–∫–∑–µ–º–ø–ª—è—Ä `GPTModel`.\n",
    "* –°–Ω–∞—á–∞–ª–∞ –º—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä `GPTModel`.\n",
    "* –í –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ GPT –ª–∏–Ω–µ–π–Ω—ã–µ —Å–ª–æ–∏ –¥–ª—è –º–∞—Ç—Ä–∏—Ü –∑–∞–ø—Ä–æ—Å–∞ (query), –∫–ª—é—á–∞ (key) –∏ –∑–Ω–∞—á–µ–Ω–∏—è (value) –≤ –º–æ–¥—É–ª–µ –º–Ω–æ–≥–æ–≥–æ–ª–æ–≤–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏—Å—å —Å –≤–µ–∫—Ç–æ—Ä–∞–º–∏ —Å–º–µ—â–µ–Ω–∏—è (bias), —á—Ç–æ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–º –∏–ª–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–º; –æ–¥–Ω–∞–∫–æ, —á—Ç–æ–±—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤–µ—Å–∞, –Ω–∞–º —Ç–∞–∫–∂–µ –Ω—É–∂–Ω–æ –≤–∫–ª—é—á–∏—Ç—å —ç—Ç–æ, —É—Å—Ç–∞–Ω–æ–≤–∏–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä `qkv_bias` –≤ –∑–Ω–∞—á–µ–Ω–∏–µ `True` –≤ –Ω–∞—à–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏.\n",
    "* –ú—ã —Ç–∞–∫–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª–∏–Ω—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ `1024` —Ç–æ–∫–µ–Ω–∞, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–∏–º–µ–Ω—è–ª–∞—Å—å –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö GPT-2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142d887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.load_state_dict(torch.load(file_name, weights_only=True))\n",
    "gpt.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea07d0c7",
   "metadata": {},
   "source": [
    "* –ï–≥–µ—Ä –º–æ–¥–µ–ª—å –¥“±—Ä—ã—Å –∂“Ø–∫—Ç–µ–ª—Å–µ, –æ–Ω—ã –±“±—Ä—ã–Ω –∂–∞–∑“ì–∞–Ω `generate` —Ñ—É–Ω–∫—Ü–∏—è–º—ã–∑ –∞—Ä“õ—ã–ª—ã –∂–∞“£–∞ –º”ô—Ç—ñ–Ω –≥–µ–Ω–µ—Ä–∞—Ü–∏—è–ª–∞—É “Ø—à—ñ–Ω –ø–∞–π–¥–∞–ª–∞–Ω—É“ì–∞ –±–æ–ª–∞–¥—ã:\n",
    "***\n",
    "* –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ, –º—ã –º–æ–∂–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ—ë –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–æ–≤–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é –Ω–∞—à–µ–π –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Ñ—É–Ω–∫—Ü–∏–∏ `generate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8732985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward finding an ideal life. You don't have to accept your problems by trying to remedy them, because that would be foolish\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479eb025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
