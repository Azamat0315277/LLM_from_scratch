{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7529a39",
   "metadata": {},
   "source": [
    "# 5. –ú–æ–¥–µ–ª—å–¥—ã –Ω–∞“õ—Ç—ã –±–∞–ø—Ç–∞—É (Fine tuning)\n",
    "# 5. –¢–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ (Fine tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4abe6a",
   "metadata": {},
   "source": [
    "* LLM –º–æ–¥–µ–ª—ñ–Ω –Ω–∞“õ—Ç—ã –±–∞–ø—Ç–∞—É –æ–Ω—ã“£ –º—ñ–Ω–µ–∑-“õ“±–ª“õ—ã–Ω —Ä–µ—Ç—Ç–µ–π–¥—ñ, “õ–æ—Å—ã–º—à–∞ –±—ñ–ª—ñ–º –µ–Ω–≥—ñ–∑–µ–¥—ñ –∂”ô–Ω–µ –±–µ–ª–≥—ñ–ª—ñ –±—ñ—Ä –¥–æ–º–µ–Ω–¥–µ—Ä –º–µ–Ω —Ç–∞–ø—Å—ã—Ä–º–∞–ª–∞—Ä“ì–∞ ”©–Ω—ñ–º–¥—ñ–ª—ñ–≥—ñ–Ω –æ“£—Ç–∞–π–ª–∞–Ω–¥—ã—Ä–∞–¥—ã. \n",
    "–ú—ã—Å–∞–ª—ã:   \n",
    "\n",
    "    * GPT-4 –±–∞–∑–∞–ª—ã“õ –º–æ–¥–µ–ª—å —Ä–µ—Ç—ñ–Ω–¥–µ “õ—ã–∑–º–µ—Ç –µ—Ç–µ–¥—ñ, –±—ñ—Ä–∞“õ OpenAI –æ–Ω—ã –Ω“±—Å“õ–∞—É–ª–∞—Ä –º–µ–Ω —Å“±—Ä–∞—É–ª–∞—Ä–¥—ã –∂–∞“õ—Å—ã—Ä–∞“õ —Ç“Ø—Å—ñ–Ω—É “Ø—à—ñ–Ω –Ω–∞“õ—Ç—ã –±–∞–ø—Ç–∞—É–¥–∞–Ω ”©—Ç–∫—ñ–∑–µ–¥—ñ. –ù”ô—Ç–∏–∂–µ—Å—ñ–Ω–¥–µ –±“Ø–≥—ñ–Ω–¥–µ –±”ô—Ä—ñ “õ–æ–ª–¥–∞–Ω–∞—Ç—ã–Ω ChatGPT-4 –ø–∞–π–¥–∞ –±–æ–ª–¥—ã.\n",
    "    * DeepSeek-R1-Distill-Llama-8B ‚Äî –±“±–ª Llama-3.1-8B –º–æ–¥–µ–ª—ñ–Ω—ñ“£ –Ω–∞“õ—Ç—ã –±–∞–ø—Ç–∞–ª“ì–∞–Ω –Ω“±—Å“õ–∞—Å—ã. DeepSeek –∫–æ–º–ø–∞–Ω–∏—è—Å—ã DeepSeek-R1 –∂–∞—Å–∞“ì–∞–Ω –¥–µ—Ä–µ–∫—Ç–µ—Ä–¥—ñ –ø–∞–π–¥–∞–ª–∞–Ω—ã–ø, Llama-3.1-8B –º–æ–¥–µ–ª—ñ–Ω –Ω–∞“õ—Ç—ã –±–∞–ø—Ç–∞—É–¥–∞–Ω ”©—Ç–∫—ñ–∑–¥—ñ. –ë“±–ª –ø—Ä–æ—Ü–µ—Å—Å –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏—è –¥–µ–ø –∞—Ç–∞–ª–∞–¥—ã (fine-tuning —ñ—à–∫—ñ —Ç“Ø—Ä—ñ), –æ–Ω–¥–∞ –¥–µ—Ä–µ–∫—Ç–µ—Ä Llama –º–æ–¥–µ–ª—ñ–Ω–µ –µ–Ω–≥—ñ–∑—ñ–ª—ñ–ø, –º–æ–¥–µ–ª—å–≥–µ –ø–∞–π—ã–º–¥–∞—É “õ–∞–±—ñ–ª–µ—Ç—ñ–Ω “Ø–π—Ä–µ—Ç–µ–¥—ñ.\n",
    "---\n",
    "* –¢–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ LLM-–º–æ–¥–µ–ª–∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –µ—ë –ø–æ–≤–µ–¥–µ–Ω–∏–µ, —Ä–∞—Å—à–∏—Ä–∏—Ç—å –∑–Ω–∞–Ω–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤ –∏ –∑–∞–¥–∞—á. \n",
    "–ù–∞–ø—Ä–∏–º–µ—Ä:    \n",
    "\n",
    "    * GPT-4 —Å–ª—É–∂–∏—Ç –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é, –æ–¥–Ω–∞–∫–æ OpenAI –ø—Ä–æ–≤–µ–ª–∞ –µ—ë —Ç–æ–Ω–∫—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É, —á—Ç–æ–±—ã –æ–Ω–∞ –ª—É—á—à–µ –ø–æ–Ω–∏–º–∞–ª–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ –∑–∞–ø—Ä–æ—Å—ã. –¢–∞–∫ –ø–æ—è–≤–∏–ª–∞—Å—å ChatGPT-4, –∫–æ—Ç–æ—Ä—É—é —Å–µ–≥–æ–¥–Ω—è –∏—Å–ø–æ–ª—å–∑—É—é—Ç –≤—Å–µ.\n",
    "    * DeepSeek-R1-Distill-Llama-8B ‚Äî —ç—Ç–æ —Ç–æ–Ω–∫–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏ Llama-3.1-8B. –ö–æ–º–ø–∞–Ω–∏—è DeepSeek –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞ –¥–∞–Ω–Ω—ã–µ, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ DeepSeek-R1, —á—Ç–æ–±—ã –¥–æ–æ–±—É—á–∏—Ç—å Llama-3.1-8B. –≠—Ç–æ—Ç –ø—Ä–æ—Ü–µ—Å—Å, –∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–∞–∫ –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏—è (–ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è fine-tuning), –≤–Ω–µ–¥—Ä—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –º–æ–¥–µ–ª—å Llama, –æ–±—É—á–∞—è –µ—ë —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—è–º –∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—é.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c893791a",
   "metadata": {},
   "source": [
    "* Fine Tuning –Ω–µ “Ø—à—ñ–Ω “õ–∞–∂–µ—Ç:   \n",
    "\n",
    "    * `–ñ–∞“£–∞—Ä—Ç—É –∂”ô–Ω–µ –∂–∞“£–∞ –±—ñ–ª—ñ–º–¥—ñ “Ø–π—Ä–µ–Ω—É`: –ñ–∞“£–∞, –¥–æ–º–µ–Ω–≥–µ —Ç”ô–Ω –∞“õ–ø–∞—Ä–∞—Ç—Ç—ã –µ–Ω–≥—ñ–∑—ñ–ø, –º–µ“£–≥–µ—Ä—É.\n",
    "    * `–ú—ñ–Ω–µ–∑-“õ“±–ª—ã“õ—Ç—ã –±–∞–ø—Ç–∞—É`: –ú–æ–¥–µ–ª—å–¥—ñ“£ —Ç–æ–Ω–∞–ª–¥—ã“ì—ã–Ω, —Ç“±–ª“ì–∞–ª—ã“õ “õ–∞—Å–∏–µ—Ç—ñ–Ω –Ω–µ–º–µ—Å–µ –∂–∞—É–∞–ø –±–µ—Ä—É —Å—Ç–∏–ª—ñ–Ω —Ä–µ—Ç—Ç–µ—É.\n",
    "    * `–¢–∞–ø—Å—ã—Ä–º–∞–ª–∞—Ä“ì–∞ –æ“£—Ç–∞–π–ª–∞–Ω–¥—ã—Ä—É`: –ù–∞“õ—Ç—ã “õ–æ–ª–¥–∞–Ω—É –∂–∞“ì–¥–∞–π–ª–∞—Ä—ã–Ω–∞ –¥”ô–ª–¥—ñ–∫ –ø–µ–Ω ”©–∑–µ–∫—Ç—ñ–ª—ñ–∫—Ç—ñ –∞—Ä—Ç—Ç—ã—Ä—É.\n",
    "---\n",
    "* –î–ª—è —á–µ–≥–æ –Ω—É–∂–µ–Ω Fine Tuning:   \n",
    "\n",
    "    * `–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –Ω–æ–≤—ã–º –∑–Ω–∞–Ω–∏—è–º`: –í–Ω–µ–¥—Ä–µ–Ω–∏–µ –∏ —É—Å–≤–æ–µ–Ω–∏–µ –Ω–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–π –¥–ª—è –¥–æ–º–µ–Ω–∞.\n",
    "    * `–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è`: –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ —Ç–æ–Ω–∞, –ª–∏—á–Ω–æ—Å—Ç–∏ –∏–ª–∏ —Å—Ç–∏–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –º–æ–¥–µ–ª–∏.\n",
    "    * `–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ–¥ –∑–∞–¥–∞—á–∏`: –ü–æ–≤—ã—à–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e118a68",
   "metadata": {},
   "source": [
    "# LORA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360259ff",
   "metadata": {},
   "source": [
    "### üß† LoRA –¥–µ–≥–µ–Ω –Ω–µ?\n",
    "\n",
    "**LoRA (Low-Rank Adaptation)** ‚Äî “Ø–ª–∫–µ–Ω —Ç—ñ–ª–¥—ñ–∫ –º–æ–¥–µ–ª—å–¥–µ—Ä–¥—ñ (LLM) **—Ç–æ–ª—ã“õ “õ–∞–π—Ç–∞ “Ø–π—Ä–µ—Ç–ø–µ–π**, —Ç–µ–∫ –∞–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–ª–µ—Ä –∞—Ä“õ—ã–ª—ã –Ω–∞“õ—Ç—ã –±–∞–ø—Ç–∞—É“ì–∞ –º“Ø–º–∫—ñ–Ω–¥—ñ–∫ –±–µ—Ä–µ—Ç—ñ–Ω ”ô–¥—ñ—Å.\n",
    "–Ø“ì–Ω–∏, –±“Ø–∫—ñ–ª –º–æ–¥–µ–ª—å–¥—ñ “õ–∞–π—Ç–∞ “Ø–π—Ä–µ—Ç—É–¥—ñ“£ –æ—Ä–Ω—ã–Ω–∞, LoRA —Ç–µ–∫ **—à–∞“ì—ã–Ω “Ø–π—Ä–µ–Ω–µ—Ç—ñ–Ω “õ–∞–±–∞—Ç—Ç–∞—Ä–¥—ã** “õ–æ—Å–∞–¥—ã.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è “ö–∞–ª–∞–π –∂“±–º—ã—Å —ñ—Å—Ç–µ–π–¥—ñ:\n",
    "\n",
    "–ú–æ–¥–µ–ª—å–¥—ñ –º–∏–ª–ª–∏–æ–Ω–¥–∞“ì–∞–Ω –Ω–µ–π—Ä–æ–Ω–Ω–∞–Ω —Ç“±—Ä–∞—Ç—ã–Ω “Ø–ª–∫–µ–Ω –º–∏ —Ä–µ—Ç—ñ–Ω–¥–µ –µ–ª–µ—Å—Ç–µ—Ç—ñ“£—ñ–∑ üß©\n",
    "\n",
    "* –î”ô—Å—Ç“Ø—Ä–ª—ñ fine-tuning: –±“Ø–∫—ñ–ª ‚Äú–º–∏–¥—ã‚Äù “õ–∞–π—Ç–∞ “Ø–π—Ä–µ—Ç–µ–¥—ñ ‚Üí “õ—ã–º–±–∞—Ç.\n",
    "* LoRA fine-tuning: —Ç–µ–∫ –±—ñ—Ä–Ω–µ—à–µ **—à–∞“ì—ã–Ω ‚Äú–∂–∞–¥—ã –∞–¥–∞–ø—Ç–µ—Ä–ª–µ—Ä—ñ–Ω‚Äù** “õ–æ—Å–∞–¥—ã ‚Üí —Ç–µ–∑ –∂”ô–Ω–µ –∞—Ä–∑–∞–Ω.\n",
    "\n",
    "–¢–µ—Ö–Ω–∏–∫–∞–ª—ã“õ —Ç“±—Ä“ì—ã–¥–∞, LoRA –º–æ–¥–µ–ª—å “õ–∞–±–∞—Ç—Ç–∞—Ä—ã–Ω–∞ –µ–∫—ñ –∫—ñ—à–∫–µ–Ω—Ç–∞–π –º–∞—Ç—Ä–∏—Ü–∞ (`A` –∂”ô–Ω–µ `B`) –µ–Ω–≥—ñ–∑–µ–¥—ñ.\n",
    "–¢–µ–∫ –æ—Å—ã –º–∞—Ç—Ä–∏—Ü–∞–ª–∞—Ä –∂–∞“£–∞—Ä—Ç—ã–ª–∞–¥—ã ‚Äî –Ω–µ–≥—ñ–∑–≥—ñ –º–æ–¥–µ–ª—å ”©–∑–≥–µ—Ä—ñ—Å—Å—ñ–∑ “õ–∞–ª–∞–¥—ã.\n",
    "\n",
    "### üí° –ú—ã—Å–∞–ª:\n",
    "\n",
    "–ê–π—Ç–∞–ª—ã“õ, –±–∞–∑–∞–ª—ã“õ –º–æ–¥–µ–ª—å –∂–∞–ª–ø—ã –∞“ì—ã–ª—à—ã–Ω —Ç—ñ–ª—ñ–Ω –±—ñ–ª–µ–¥—ñ.\n",
    "–°—ñ–∑ –æ–Ω—ã **–º–µ–¥–∏—Ü–∏–Ω–∞ —Å–∞–ª–∞—Å—ã–Ω–¥–∞“ì—ã** —Å“±—Ä–∞“õ—Ç–∞—Ä“ì–∞ –∂–∞—É–∞–ø –±–µ—Ä—É–≥–µ “Ø–π—Ä–µ—Ç–∫—ñ“£—ñ–∑ –∫–µ–ª–µ–¥—ñ.\n",
    "–ë“Ø–∫—ñ–ª –º–æ–¥–µ–ª—å–¥—ñ “õ–∞–π—Ç–∞ “Ø–π—Ä–µ—Ç—É–¥—ñ“£ –æ—Ä–Ω—ã–Ω–∞, LoRA:\n",
    "\n",
    "1. –ù–µ–≥—ñ–∑–≥—ñ —Å–∞–ª–º–∞“õ—Ç–∞—Ä–¥—ã “õ–∞—Ç—ã—Ä–∞–¥—ã.\n",
    "2. **–ú–µ–¥–∏—Ü–∏–Ω–∞–ª—ã“õ –±—ñ–ª—ñ–º–¥—ñ** “Ø–π—Ä–µ–Ω–µ—Ç—ñ–Ω –∞–¥–∞–ø—Ç–µ—Ä–ª–µ—Ä–¥—ñ “õ–æ—Å–∞–¥—ã.\n",
    "3. –ñ“±–º—ã—Å –∫–µ–∑—ñ–Ω–¥–µ –º–æ–¥–µ–ª—å –µ–∫–µ—É—ñ–Ω –±—ñ—Ä—ñ–∫—Ç—ñ—Ä–µ–¥—ñ:\n",
    "   *–Ω–µ–≥—ñ–∑–≥—ñ –±—ñ–ª—ñ–º + –º–µ–¥–∏—Ü–∏–Ω–∞–ª—ã“õ LoRA –∂–∞“£–∞—Ä—Ç—É–ª–∞—Ä—ã*.\n",
    "\n",
    "\n",
    "\n",
    "### üöÄ –ù–µ–ª—ñ–∫—Ç–µ–Ω LoRA –ø–∞–π–¥–∞–ª–∞–Ω—ã–ª–∞–¥—ã:\n",
    "\n",
    "* **–¢–∏—ñ–º–¥—ñ:** GPU –∂–∞–¥—ã–Ω –∞–∑ –ø–∞–π–¥–∞–ª–∞–Ω–∞–¥—ã.\n",
    "* **–ñ—ã–ª–¥–∞–º:** –°–∞“ì–∞—Ç—Ç–∞—Ä–¥–∞ “Ø–π—Ä–µ–Ω–µ–¥—ñ, –∫“Ø–Ω–¥–µ—Ä –µ–º–µ—Å.\n",
    "* **–ò–∫–µ–º–¥—ñ:** ”ò—Ä—Ç“Ø—Ä–ª—ñ –∞–¥–∞–ø—Ç–µ—Ä–ª–µ—Ä–¥—ñ –∞—É—ã—Å—Ç—ã—Ä—É“ì–∞ –±–æ–ª–∞–¥—ã ‚Äî –º—ã—Å–∞–ª—ã, –∑–∞“£, “õ–∞—Ä–∂—ã —Ç.–±. “Ø—à—ñ–Ω.\n",
    "\n",
    "---\n",
    "### üß† –ß—Ç–æ —Ç–∞–∫–æ–µ LoRA?\n",
    "\n",
    "**LoRA (Low-Rank Adaptation)** ‚Äî —ç—Ç–æ —Å–ø–æ—Å–æ–± —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM) **–±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è**.\n",
    "–í–º–µ—Å—Ç–æ —Ç–æ–≥–æ —á—Ç–æ–±—ã –∏–∑–º–µ–Ω—è—Ç—å –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏, LoRA –¥–æ–±–∞–≤–ª—è–µ—Ç **–Ω–µ–±–æ–ª—å—à–∏–µ –æ–±—É—á–∞–µ–º—ã–µ —Å–ª–æ–∏** –ø–æ–≤–µ—Ä—Ö —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö.\n",
    "\n",
    "\n",
    "### ‚öôÔ∏è –ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:\n",
    "\n",
    "–ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ –º–æ–¥–µ–ª—å –∫–∞–∫ –æ–≥—Ä–æ–º–Ω—ã–π –º–æ–∑–≥ —Å –º–∏–ª–ª–∏–æ–Ω–∞–º–∏ –Ω–µ–π—Ä–æ–Ω–æ–≤ üß©\n",
    "\n",
    "* –û–±—ã—á–Ω–æ–µ fine-tuning: –ø–µ—Ä–µ–æ–±—É—á–∞–µ—Ç **–≤–µ—Å—å –º–æ–∑–≥** ‚Üí –¥–æ—Ä–æ–≥–æ.\n",
    "* LoRA fine-tuning: –¥–æ–±–∞–≤–ª—è–µ—Ç –ª–∏—à—å –Ω–µ—Å–∫–æ–ª—å–∫–æ **–º–∞–ª–µ–Ω—å–∫–∏—Ö ‚Äú–∞–¥–∞–ø—Ç–µ—Ä–æ–≤ –ø–∞–º—è—Ç–∏‚Äù** ‚Üí –±—ã—Å—Ç—Ä–æ –∏ –¥–µ—à–µ–≤–æ.\n",
    "\n",
    "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏, LoRA –≤—Å—Ç–∞–≤–ª—è–µ—Ç –¥–≤–µ –º–∞–ª–µ–Ω—å–∫–∏–µ –º–∞—Ç—Ä–∏—Ü—ã (`A` –∏ `B`) –≤ —Å–ª–æ–∏ –º–æ–¥–µ–ª–∏.\n",
    "–û–±–Ω–æ–≤–ª—è—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –æ–Ω–∏ ‚Äî –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –æ—Å—Ç–∞—ë—Ç—Å—è –∑–∞–º–æ—Ä–æ–∂–µ–Ω–Ω–æ–π.\n",
    "\n",
    "### üí° –ü—Ä–∏–º–µ—Ä:\n",
    "\n",
    "–î–æ–ø—É—Å—Ç–∏–º, –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –∑–Ω–∞–µ—Ç –æ–±—â–∏–π –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —è–∑—ã–∫.\n",
    "–í—ã —Ö–æ—Ç–∏—Ç–µ, —á—Ç–æ–±—ã –æ–Ω–∞ –æ—Ç–≤–µ—á–∞–ª–∞ –Ω–∞ **–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ** –≤–æ–ø—Ä–æ—Å—ã.\n",
    "–í–º–µ—Å—Ç–æ –ø–æ–ª–Ω–æ–≥–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è LoRA:\n",
    "\n",
    "1. –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ—Ç –±–∞–∑–æ–≤—ã–µ –≤–µ—Å–∞.\n",
    "2. –î–æ–±–∞–≤–ª—è–µ—Ç –∞–¥–∞–ø—Ç–µ—Ä—ã, –æ–±—É—á–∞—é—â–∏–µ—Å—è **–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–º –∑–Ω–∞–Ω–∏—è–º**.\n",
    "3. –ü—Ä–∏ —Ä–∞–±–æ—Ç–µ –º–æ–¥–µ–ª—å –∫–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç –æ–±–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞:\n",
    "   *–±–∞–∑–æ–≤—ã–µ –∑–Ω–∞–Ω–∏—è + –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è LoRA*.\n",
    "\n",
    "\n",
    "\n",
    "### üöÄ –ü–æ—á–µ–º—É —Å—Ç–æ–∏—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LoRA:\n",
    "\n",
    "* **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ:** –¢—Ä–µ–±—É–µ—Ç –º–µ–Ω—å—à–µ GPU-–ø–∞–º—è—Ç–∏.\n",
    "* **–ë—ã—Å—Ç—Ä–æ:** –î–æ–æ–±—É—á–µ–Ω–∏–µ –∑–∞–Ω–∏–º–∞–µ—Ç —á–∞—Å—ã, –∞ –Ω–µ –¥–Ω–∏.\n",
    "* **–ì–∏–±–∫–æ:** –ú–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å –∞–¥–∞–ø—Ç–µ—Ä—ã ‚Äî –Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –∏–ª–∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –∑–∞–¥–∞—á.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929cb91d",
   "metadata": {},
   "source": [
    "![LORA](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38028faa",
   "metadata": {},
   "source": [
    "* –ú–æ–¥–µ–ª—å–¥—ã“£ –±–∞—Å—Ç–∞–ø“õ—ã —Å–∞–ª–º–∞“õ—Ç–∞—Ä—ã:\n",
    "* –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏:  \n",
    "\n",
    "    $x_i  = W  \\mathbin{@}  input$\n",
    "\n",
    "* –ù–∞“õ—Ç—ã –±–∞–ø—Ç–∞—É–¥–∞–Ω ”©—Ç–∫–µ–Ω –º–æ–¥–µ–ª—å (Fine Tuning):    \n",
    "* –ú–æ–¥–µ–ª—å –ø–æ—Å–ª–µ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (Fine Tuning):    \n",
    "\n",
    "    $x_i = W \\mathbin{@}  input + (B \\mathbin{@} A) \\mathbin{@}  input$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e178e1f7",
   "metadata": {},
   "source": [
    "# Unsloth –∞—Ä“õ—ã–ª—ã –Ω–∞“õ—Ç—ã –±–∞–ø—Ç–∞—É\n",
    "# –¢–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —Å Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a86c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os, re\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth\n",
    "else:\n",
    "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
    "    import torch; v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
    "    xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
    "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
    "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
    "    !pip install --no-deps unsloth\n",
    "!pip install transformers==4.56.2\n",
    "!pip install --no-deps trl==0.22.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastModel\n",
    "import torch\n",
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"unsloth/gemma-3-4b-it\",\n",
    "    max_seq_length = 2048, # Choose any for long context!\n",
    "    load_in_4bit = True,  # 4 bit quantization to reduce memory\n",
    "    load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory\n",
    "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787986d6",
   "metadata": {},
   "source": [
    "* `max_seg_length` - –ú–æ–¥–µ–ª—å –±—ñ—Ä —É–∞“õ—ã—Ç—Ç–∞ ”©“£–¥–µ–π –∞–ª–∞—Ç—ã–Ω –º–∞–∫—Å–∏–º–∞–ª–¥—ã —Ç–æ–∫–µ–Ω–¥–µ—Ä —Å–∞–Ω—ã.  \n",
    "* `load_in_4bit` - –º–æ–¥–µ–ª—å–¥—ñ“£ —Å–∞–ª–º–∞“õ—Ç–∞—Ä—ã –∞–∑ –¥”ô–ª–¥—ñ–∫–ø–µ–Ω –∂“Ø–∫—Ç–µ–π–¥—ñ, GPU –∂–∞–¥—ã–Ω –∞–∑ –ø–∞–π–¥–∞–ª–∞–Ω–∞–¥—ã.\n",
    "* `load_in_8bit` - –ú–æ–¥–µ–ª—å–¥—ñ 8-–±–∏—Ç—Ç—ñ–∫ –¥”ô–ª–¥—ñ–∫–ø–µ–Ω –∂“Ø–∫—Ç–µ–π–¥—ñ ‚Äî –±“±–ª 4-–±–∏—Ç–∫–µ “õ–∞—Ä–∞“ì–∞–Ω–¥–∞ –¥”ô–ª—ñ—Ä–µ–∫, –±—ñ—Ä–∞“õ –∫”©–±—ñ—Ä–µ–∫ –∂–∞–¥—Ç—ã –ø–∞–π–¥–∞–ª–∞–Ω–∞–¥—ã (—à–∞–º–∞–º–µ–Ω 2 –µ—Å–µ –∫”©–ø).\n",
    "* `full_finetuning`:\n",
    "    * `True` –±–æ–ª—Å–∞ ‚Äî –º–æ–¥–µ–ª—å–¥—ñ“£ –±–∞—Ä–ª—ã“õ –ø–∞—Ä–∞–º–µ—Ç—Ä–ª–µ—Ä—ã “Ø–π—Ä–µ—Ç—ñ–ª–µ–¥—ñ.\n",
    "    * `False` –±–æ–ª—Å–∞ ‚Äî –Ω–µ–≥—ñ–∑–≥—ñ –º–æ–¥–µ–ª—å “õ–∞—Ç—ã—Ä—ã–ª–∞–¥—ã, —Ç–µ–∫ –∞–¥–∞–ø—Ç–µ—Ä–ª–µ—Ä “Ø–π—Ä–µ–Ω–µ–¥—ñ (–º—ã—Å–∞–ª—ã LoRA).\n",
    "---\n",
    "* `max_seg_length` - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞ –æ–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥  \n",
    "* `load_in_4bit` - —É–º–µ–Ω—å—à–∞–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU-–ø–∞–º—è—Ç–∏, —Å–æ—Ö—Ä–∞–Ω—è—è –≤–µ—Å–∞ —Å –º–µ–Ω—å—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é.\n",
    "* `load_in_8bit` - —Ç–æ—á–Ω–µ–µ, —á–µ–º 4-–±–∏—Ç, –Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤ 2 —Ä–∞–∑–∞ –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏.\n",
    "* `full_finetuning`:\n",
    "    * –ï—Å–ª–∏ `True` ‚Äî –æ–±—É—á–∞—é—Ç—Å—è –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏.\n",
    "    * –ï—Å–ª–∏ `False` ‚Äî –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å \"–∑–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ—Ç—Å—è\", –æ–±—É—á–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –∞–¥–∞–ø—Ç–µ—Ä—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, LoRA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dfd4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = False, # Turn off for just text!\n",
    "    finetune_language_layers   = True,  # Should leave on!\n",
    "    finetune_attention_modules = True,  # Attention good for GRPO\n",
    "    finetune_mlp_modules       = True,  # SHould leave on always!\n",
    "\n",
    "    r = 8,           # Larger = higher accuracy, but might overfit\n",
    "    lora_alpha = 8,  # Recommended alpha == r at least\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e08c05",
   "metadata": {},
   "source": [
    "* `finetune_language_layers = True`: –¢—ñ–ª–¥—ñ–∫ “õ–∞–±–∞—Ç—Ç–∞—Ä–¥—ã “Ø–π—Ä–µ—Ç–µ–º—ñ–∑, —Å–µ–±–µ–±—ñ –º”ô—Ç—ñ–Ω–¥—ñ —Ç“Ø—Å—ñ–Ω—É–¥–µ –Ω–µ–≥—ñ–∑–≥—ñ —Ä”©–ª–¥–µ.\n",
    "* `finetune_attention_modules = True`: Attention “õ–∞–±–∞—Ç—Ç–∞—Ä—ã–Ω “Ø–π—Ä–µ—Ç–µ–º—ñ–∑ ‚Äî –º–æ–¥–µ–ª—å –º–∞“£—ã–∑–¥—ã —Å”©–∑–¥–µ—Ä–≥–µ –∂–∞“õ—Å—ã—Ä–∞“õ –Ω–∞–∑–∞—Ä –∞—É–¥–∞—Ä–∞–¥—ã.\n",
    "* `finetune_mlp_modules = True`: MLP (feed-forward) “õ–∞–±–∞—Ç—Ç–∞—Ä—ã–Ω “Ø–π—Ä–µ—Ç–µ–º—ñ–∑ ‚Äî —Ç–æ–∫–µ–Ω–¥–µ—Ä –∞—Ä–∞—Å—ã–Ω–¥–∞“ì—ã –±–∞–π–ª–∞–Ω—ã—Å—Ç–∞—Ä–¥—ã –∂–∞“õ—Å—ã “Ø–π—Ä–µ–Ω—É–≥–µ –∫”©–º–µ–∫—Ç–µ—Å–µ–¥—ñ.\n",
    "* `r = 8`: LoRA —Ä–∞–Ω–≥—ñ ‚Äî –∂–∞“£–∞ –∞“õ–ø–∞—Ä–∞—Ç –∫”©–ª–µ–º—ñ–Ω –∞–Ω—ã“õ—Ç–∞–π–¥—ã. “Æ–ª–∫–µ–Ω –º”ô–Ω ‚Äî –¥”ô–ª–¥—ñ–∫ –∂–æ“ì–∞—Ä—ã, –±—ñ—Ä–∞“õ overfitting “õ–∞—É–ø—ñ –¥–µ –±–∞—Ä.\n",
    "* `lora_alpha = 8`: LoRA –∂–∞“£–∞—Ä—Ç—É–ª–∞—Ä—ã–Ω –º–∞—Å—à—Ç–∞–±—Ç–∞—É –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ñ (”ô–¥–µ—Ç—Ç–µ r-–º–µ–Ω —Ç–µ“£).\n",
    "* l`ora_dropout = 0`: Dropout “õ–æ–ª–¥–∞–Ω–±–∞–π–º—ã–∑ ‚Äî LoRA “Ø—à—ñ–Ω —Ç–∏—ñ–º–¥—ñ.\n",
    "* `bias = \"none\"`: Bias –ø–∞—Ä–∞–º–µ—Ç—Ä–ª–µ—Ä—ñ–Ω “Ø–π—Ä–µ—Ç–ø–µ–π–º—ñ–∑ (–∂–∞–¥ “Ø–Ω–µ–º–¥–µ–π–¥—ñ).\n",
    "* `random_state = 3407`: –ù”ô—Ç–∏–∂–µ–ª–µ—Ä–¥—ñ “õ–∞–π—Ç–∞–ª–∞—É “Ø—à—ñ–Ω –∫–µ–∑–¥–µ–π—Å–æ“õ —Å–∞–Ω–¥–∞—Ä –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã–Ω—ã“£ —Ç“±“õ—ã–º—ã.\n",
    "---\n",
    "* `finetune_vision_layers = False`: –ù–µ –æ–±—É—á–∞–µ–º –≤–∏–∑—É–∞–ª—å–Ω—É—é —á–∞—Å—Ç—å ‚Äî —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç.\n",
    "* `finetune_language_layers = True`: –û–±—É—á–∞–µ–º —è–∑—ã–∫–æ–≤—ã–µ —Å–ª–æ–∏ ‚Äî –æ–Ω–∏ –æ—Ç–≤–µ—á–∞—é—Ç –∑–∞ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞.\n",
    "* `finetune_attention_modules = True`: –û–±—É—á–∞–µ–º attention-—Å–ª–æ–∏ ‚Äî –º–æ–¥–µ–ª—å –ª—É—á—à–µ —Ñ–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –≤–∞–∂–Ω—ã—Ö —Å–ª–æ–≤–∞—Ö.\n",
    "* `finetune_mlp_modules = True`: –û–±—É—á–∞–µ–º MLP-—Å–ª–æ–∏ ‚Äî –ø–æ–º–æ–≥–∞–µ—Ç —É–ª—É—á—à–∏—Ç—å —Å–≤—è–∑–∏ –º–µ–∂–¥—É —Ç–æ–∫–µ–Ω–∞–º–∏.\n",
    "* `r = 8`: –†–∞–Ω–≥ LoRA ‚Äî —Å–∫–æ–ª—å–∫–æ –Ω–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–æ–±–∞–≤–ª—è–µ–º. –ë–æ–ª—å—à–µ = –≤—ã—à–µ —Ç–æ—á–Ω–æ—Å—Ç—å, –Ω–æ –∏ —Ä–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è.\n",
    "* `lora_alpha = 8`: –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π LoRA (–æ–±—ã—á–Ω–æ —Ä–∞–≤–µ–Ω r).\n",
    "* `lora_dropout = 0`: –ë–µ–∑ dropout ‚Äî –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è LoRA.\n",
    "* `bias = \"none\"`: –ù–µ –æ–±—É—á–∞–µ–º bias-–ø–∞—Ä–∞–º–µ—Ç—Ä—ã (—ç–∫–æ–Ω–æ–º–∏—Ç –ø–∞–º—è—Ç—å).\n",
    "* `random_state = 3407`: –§–∏–∫—Å–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9d7368",
   "metadata": {},
   "source": [
    "* –ï–Ω–¥—ñ –±—ñ–∑ –¥–∏–∞–ª–æ–≥ —Å—Ç–∏–ª—ñ–Ω–¥–µ–≥—ñ fine-tuning “Ø—à—ñ–Ω `Gemma-3` –ø—ñ—à—ñ–º—ñ–Ω “õ–æ–ª–¥–∞–Ω–∞–º—ã–∑. –ë—ñ–∑ [Maxime Labonne's FineTome-100k](https://huggingface.co/datasets/mlabonne/FineTome-100k) –¥–µ—Ä–µ–∫—Ç–µ—Ä –∂–∏—ã–Ω—ã–Ω  –ø–∞–π–¥–∞–ª–∞–Ω–∞–º—ã–∑. \n",
    "* `Gemma-3` –¥–∏–∞–ª–æ–≥—Ç–∞—Ä–¥—ã —Ç”©–º–µ–Ω–¥–µ–≥—ñ–¥–µ–π —Ñ–æ—Ä–º–∞—Ç“õ–∞ –∫–µ–ª—Ç—ñ—Ä–µ–¥—ñ:\n",
    "\n",
    "    ```\n",
    "    <bos><start_of_turn>user\n",
    "    Hello!<end_of_turn>\n",
    "    <start_of_turn>model\n",
    "    Hey there!<end_of_turn>\n",
    "    ```\n",
    "\n",
    "---\n",
    "–¢–µ–ø–µ—Ä—å –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–æ—Ä–º–∞—Ç `Gemma-3` –¥–ª—è —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ —Å—Ç–∏–ª–µ –¥–∏–∞–ª–æ–≥–æ–≤. \n",
    "* –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö [Maxime Labonne's FineTome-100k](https://huggingface.co/datasets/mlabonne/FineTome-100k) –≤ —Å—Ç–∏–ª–µ ShareGPT. \n",
    "* `Gemma-3` –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –º–Ω–æ–≥–æ—à–∞–≥–æ–≤—ã–µ –¥–∏–∞–ª–æ–≥–∏ —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:\n",
    "\n",
    "    ```\n",
    "    <bos><start_of_turn>user\n",
    "    Hello!<end_of_turn>\n",
    "    <start_of_turn>model\n",
    "    Hey there!<end_of_turn>\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baade026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"gemma-3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e4868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"mlabonne/FineTome-100k\", split = \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd61f0d",
   "metadata": {},
   "source": [
    "* –ï–Ω–¥—ñ –±—ñ–∑ fine-tuning –∂–∞—Å–∞—É “Ø—à—ñ–Ω –¥–µ—Ä–µ–∫—Ç–µ—Ä –∂–∏—ã–Ω—ã–Ω –¥“±—Ä—ã—Å –ø—ñ—à—ñ–º–≥–µ —Ç“Ø—Ä–ª–µ–Ω–¥—ñ—Ä—É –º–∞“õ—Å–∞—Ç—ã–Ω–¥–∞ `standardize_data_formats` —Ñ—É–Ω–∫—Ü–∏—è—Å—ã–Ω “õ–æ–ª–¥–∞–Ω–∞–º—ã–∑!\n",
    "---\n",
    "* –¢–µ–ø–µ—Ä—å –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é `standardize_data_formats`, —á—Ç–æ–±—ã –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f97581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import standardize_data_formats\n",
    "dataset = standardize_data_formats(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e3793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc0c9aa",
   "metadata": {},
   "source": [
    "* –ï–Ω–¥—ñ –±—ñ–∑ `Gemma-3` “Ø—à—ñ–Ω —á–∞—Ç “Ø–ª–≥—ñ—Å—ñ–Ω –¥–∏–∞–ª–æ–≥—Ç–∞—Ä“ì–∞ “õ–æ–ª–¥–∞–Ω—É—ã–º—ã–∑ –∫–µ—Ä–µ–∫ –∂”ô–Ω–µ –æ–Ω—ã `text` –∞–π–Ω–∞–ª–º–∞—Å—ã–Ω–∞ —Å–∞“õ—Ç–∞–π–º—ã–∑. Fine-tuning –∫–µ–∑—ñ–Ω–¥–µ `<bos>` —Ç–∞“£–±–∞—Å—ã–Ω removeprefix(`'<bos>'`) –∞—Ä“õ—ã–ª—ã –∞–ª—ã–ø —Ç–∞—Å—Ç–∞–π–º—ã–∑. –°–µ–±–µ–±—ñ, Processor –±“±–ª –±–µ–ª–≥—ñ–Ω—ñ –æ“õ—ã—Ç—É –∞–ª–¥—ã–Ω–¥–∞ ”©–∑—ñ “õ–æ—Å–∞–¥—ã –∂”ô–Ω–µ –º–æ–¥–µ–ª—å —Ç–µ–∫ –±—ñ—Ä–µ—É—ñ–Ω –∫“Ø—Ç–µ–¥—ñ.\n",
    "---\n",
    "* –¢–µ–ø–µ—Ä—å –Ω–∞–º –Ω—É–∂–Ω–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å —à–∞–±–ª–æ–Ω —á–∞—Ç–∞ –¥–ª—è `Gemma-3` –∫ –¥–∏–∞–ª–æ–≥–∞–º –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é `text`. –ú—ã —É–¥–∞–ª—è–µ–º —Ç–æ–∫–µ–Ω `<bos>` —Å –ø–æ–º–æ—â—å—é removeprefix(`'<bos>'`), —Ç–∞–∫ –∫–∞–∫ –ø—Ä–∏ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–µ Processor —Å–∞–º –¥–æ–±–∞–≤–∏—Ç —ç—Ç–æ—Ç —Ç–æ–∫–µ–Ω –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º, –∏ –º–æ–¥–µ–ª—å –æ–∂–∏–¥–∞–µ—Ç —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175fcf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(examples):\n",
    "   convos = examples[\"conversations\"]\n",
    "   texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False).removeprefix('<bos>') for convo in convos]\n",
    "   return { \"text\" : texts, }\n",
    "\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64e088a",
   "metadata": {},
   "source": [
    "## –ú–æ–¥–µ–ª—å –∂–∞—Ç—Ç—ã“õ—Ç—ã—Ä—É\n",
    "## –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fe7166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    eval_dataset = None, # Can set up evaluation!\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field = \"text\",\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4, # Use GA to mimic batch size!\n",
    "        warmup_steps = 5,\n",
    "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 30,\n",
    "        learning_rate = 2e-4, # Reduce to 2e-5 for long training runs\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.001,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        report_to = \"none\", # Use TrackIO/WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668e2e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import train_on_responses_only\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<start_of_turn>user\\n\",\n",
    "    response_part = \"<start_of_turn>model\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70116ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a6dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"gemma-3\",\n",
    ")\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\n",
    "        \"type\" : \"text\",\n",
    "        \"text\" : \"Continue the sequence: 1, 1, 2, 3, 5, 8,\",\n",
    "    }]\n",
    "}]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    tokenize = True,\n",
    "    return_tensors = \"pt\",\n",
    "    return_dict = True,\n",
    ")\n",
    "outputs = model.generate(\n",
    "    **inputs.to(\"cuda\"),\n",
    "    max_new_tokens = 64, # Increase for longer outputs!\n",
    "    # Recommended Gemma-3 settings!\n",
    "    temperature = 1.0, top_p = 0.95, top_k = 64,\n",
    ")\n",
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a57f0c8",
   "metadata": {},
   "source": [
    "## –ì–µ–Ω–µ—Ä–∞—Ü–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72c9037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"gemma-3\",\n",
    ")\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\n",
    "        \"type\" : \"text\",\n",
    "        \"text\" : \"Continue the sequence: 1, 1, 2, 3, 5, 8,\",\n",
    "    }]\n",
    "}]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    tokenize = True,\n",
    "    return_tensors = \"pt\",\n",
    "    return_dict = True,\n",
    ")\n",
    "outputs = model.generate(\n",
    "    **inputs.to(\"cuda\"),\n",
    "    max_new_tokens = 64, # Increase for longer outputs!\n",
    "    # Recommended Gemma-3 settings!\n",
    "    temperature = 1.0, top_p = 0.95, top_k = 64,\n",
    ")\n",
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fe4890",
   "metadata": {},
   "source": [
    "* –°–æ–Ω–¥–∞–π-–∞“õ, “Ø–∑–¥—ñ–∫—Å—ñ–∑ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è “Ø—à—ñ–Ω `TextStreamer` –ø–∞–π–¥–∞–ª–∞–Ω—É“ì–∞ –±–æ–ª–∞–¥—ã ‚Äî –±“±–ª –±“Ø–∫—ñ–ª –Ω”ô—Ç–∏–∂–µ–Ω—ñ –∫“Ø—Ç–ø–µ–π, –º”ô—Ç—ñ–Ω–Ω—ñ“£ ”ô—Ä–±—ñ—Ä —Ç–æ–∫–µ–Ω—ñ–Ω –±—ñ—Ä—Ç—ñ–Ω–¥–µ–ø –∫”©—Ä—É–≥–µ –º“Ø–º–∫—ñ–Ω–¥—ñ–∫ –±–µ—Ä–µ–¥—ñ!\n",
    "---\n",
    "* –¢–∞–∫–∂–µ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `TextStreamer` –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ ‚Äî —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç–æ–∫–µ–Ω –∑–∞ —Ç–æ–∫–µ–Ω–æ–º, –Ω–µ –¥–æ–∂–∏–¥–∞—è—Å—å –ø–æ–ª–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b45951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"type\" : \"text\", \"text\" : \"Why is the sky blue?\",}]\n",
    "}]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    tokenize = True,\n",
    "    return_tensors = \"pt\",\n",
    "    return_dict = True,\n",
    ")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "_ = model.generate(\n",
    "    **inputs.to(\"cuda\"),\n",
    "    max_new_tokens = 64, # Increase for longer outputs!\n",
    "    # Recommended Gemma-3 settings!\n",
    "    temperature = 1.0, top_p = 0.95, top_k = 64,\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a2530b",
   "metadata": {},
   "source": [
    "# Ca“õ—Ç–∞—É\n",
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe258241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Format\n",
    "if False: # Change to True to save finetune!\n",
    "    model.save_pretrained_merged(\"gemma-3-finetune\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3daba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LLama.cpp / GGUF\n",
    "if False: # Change to True to save to GGUF\n",
    "    model.save_pretrained_gguf(\n",
    "        \"gemma-3-finetune\",\n",
    "        tokenizer,\n",
    "        quantization_method = \"Q8_0\", # For now only Q8_0, BF16, F16 supported\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
